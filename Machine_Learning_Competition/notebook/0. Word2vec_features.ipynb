{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb98ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cad6933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_num_features_train.csv\" , encoding = 'utf-8')\n",
    "X_test = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_num_features_test.csv\" , encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6bd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 평가데이터 불러오기\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "target = pd.read_csv(os.path.abspath(\"../input\")+\"/y_train.csv\" , encoding = 'cp949').group\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+\"/y_train.csv\" , encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc60115",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7911fdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>sales_month</th>\n",
       "      <th>sales_day</th>\n",
       "      <th>sales_dayofweek</th>\n",
       "      <th>sales_time</th>\n",
       "      <th>str_nm</th>\n",
       "      <th>goodcd</th>\n",
       "      <th>brd_nm</th>\n",
       "      <th>corner_nm</th>\n",
       "      <th>pc_nm</th>\n",
       "      <th>part_nm</th>\n",
       "      <th>team_nm</th>\n",
       "      <th>buyer_nm</th>\n",
       "      <th>import_flg</th>\n",
       "      <th>tot_amt</th>\n",
       "      <th>dis_amt</th>\n",
       "      <th>net_amt</th>\n",
       "      <th>inst_mon</th>\n",
       "      <th>inst_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>일</td>\n",
       "      <td>1212</td>\n",
       "      <td>무역점</td>\n",
       "      <td>2116050008000</td>\n",
       "      <td>에스티로더</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>화장품</td>\n",
       "      <td>명품잡화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>1</td>\n",
       "      <td>90000</td>\n",
       "      <td>9000</td>\n",
       "      <td>81000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>일</td>\n",
       "      <td>1242</td>\n",
       "      <td>무역점</td>\n",
       "      <td>4125440008000</td>\n",
       "      <td>시슬리</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>화장품</td>\n",
       "      <td>명품잡화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>1</td>\n",
       "      <td>39000</td>\n",
       "      <td>3900</td>\n",
       "      <td>35100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>토</td>\n",
       "      <td>1810</td>\n",
       "      <td>본점</td>\n",
       "      <td>2116052008000</td>\n",
       "      <td>크리니크</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>화장품</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>1</td>\n",
       "      <td>175000</td>\n",
       "      <td>17500</td>\n",
       "      <td>157500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>토</td>\n",
       "      <td>1830</td>\n",
       "      <td>본점</td>\n",
       "      <td>4106430119900</td>\n",
       "      <td>듀퐁</td>\n",
       "      <td>수입의류</td>\n",
       "      <td>명품토탈</td>\n",
       "      <td>잡화파트</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>수입명품</td>\n",
       "      <td>1</td>\n",
       "      <td>455000</td>\n",
       "      <td>45500</td>\n",
       "      <td>409500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>일</td>\n",
       "      <td>1802</td>\n",
       "      <td>무역점</td>\n",
       "      <td>2139141008000</td>\n",
       "      <td>랑콤</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>화장품</td>\n",
       "      <td>명품잡화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>90000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040034</th>\n",
       "      <td>49993</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>수</td>\n",
       "      <td>1750</td>\n",
       "      <td>신촌점</td>\n",
       "      <td>4405551020474</td>\n",
       "      <td>톰키드</td>\n",
       "      <td>아동</td>\n",
       "      <td>아동</td>\n",
       "      <td>아동문화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>유아동복</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040035</th>\n",
       "      <td>49993</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>수</td>\n",
       "      <td>1833</td>\n",
       "      <td>신촌점</td>\n",
       "      <td>2139140008300</td>\n",
       "      <td>폴로화장품</td>\n",
       "      <td>향수</td>\n",
       "      <td>화장품</td>\n",
       "      <td>패션잡화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>0</td>\n",
       "      <td>70000</td>\n",
       "      <td>3500</td>\n",
       "      <td>66500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040036</th>\n",
       "      <td>49994</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>토</td>\n",
       "      <td>1750</td>\n",
       "      <td>본점</td>\n",
       "      <td>4230120011274</td>\n",
       "      <td>스테파넬</td>\n",
       "      <td>영트랜드</td>\n",
       "      <td>영트렌디</td>\n",
       "      <td>케주얼,구두,아동</td>\n",
       "      <td>의류패션팀</td>\n",
       "      <td>영캐주얼</td>\n",
       "      <td>0</td>\n",
       "      <td>39000</td>\n",
       "      <td>0</td>\n",
       "      <td>39000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040037</th>\n",
       "      <td>49994</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>토</td>\n",
       "      <td>1810</td>\n",
       "      <td>본점</td>\n",
       "      <td>4409271026010</td>\n",
       "      <td>써스데이아일앤드</td>\n",
       "      <td>진케주얼</td>\n",
       "      <td>진케주얼</td>\n",
       "      <td>케주얼,구두,아동</td>\n",
       "      <td>의류패션팀</td>\n",
       "      <td>유니캐주얼</td>\n",
       "      <td>0</td>\n",
       "      <td>34200</td>\n",
       "      <td>0</td>\n",
       "      <td>34200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040038</th>\n",
       "      <td>49994</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>일</td>\n",
       "      <td>1602</td>\n",
       "      <td>무역점</td>\n",
       "      <td>2116052008000</td>\n",
       "      <td>크리니크</td>\n",
       "      <td>수입종합화장품</td>\n",
       "      <td>화장품</td>\n",
       "      <td>명품잡화</td>\n",
       "      <td>잡화가용팀</td>\n",
       "      <td>화장품</td>\n",
       "      <td>1</td>\n",
       "      <td>86000</td>\n",
       "      <td>8600</td>\n",
       "      <td>77400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040039 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         custid  sales_month  sales_day sales_dayofweek  sales_time str_nm  \\\n",
       "0             0            6         25               일        1212    무역점   \n",
       "1             0            6         25               일        1242    무역점   \n",
       "2             0            8         26               토        1810     본점   \n",
       "3             0            8         26               토        1830     본점   \n",
       "4             0            9          3               일        1802    무역점   \n",
       "...         ...          ...        ...             ...         ...    ...   \n",
       "1040034   49993           13         31               수        1750    신촌점   \n",
       "1040035   49993           13         31               수        1833    신촌점   \n",
       "1040036   49994           16         14               토        1750     본점   \n",
       "1040037   49994           16         14               토        1810     본점   \n",
       "1040038   49994           16         15               일        1602    무역점   \n",
       "\n",
       "                goodcd    brd_nm corner_nm pc_nm    part_nm team_nm buyer_nm  \\\n",
       "0        2116050008000     에스티로더   수입종합화장품   화장품       명품잡화   잡화가용팀      화장품   \n",
       "1        4125440008000       시슬리   수입종합화장품   화장품       명품잡화   잡화가용팀      화장품   \n",
       "2        2116052008000      크리니크   수입종합화장품   화장품       잡화파트   잡화가용팀      화장품   \n",
       "3        4106430119900        듀퐁      수입의류  명품토탈       잡화파트   잡화가용팀     수입명품   \n",
       "4        2139141008000        랑콤   수입종합화장품   화장품       명품잡화   잡화가용팀      화장품   \n",
       "...                ...       ...       ...   ...        ...     ...      ...   \n",
       "1040034  4405551020474       톰키드        아동    아동       아동문화   잡화가용팀     유아동복   \n",
       "1040035  2139140008300     폴로화장품        향수   화장품       패션잡화   잡화가용팀      화장품   \n",
       "1040036  4230120011274      스테파넬      영트랜드  영트렌디  케주얼,구두,아동   의류패션팀     영캐주얼   \n",
       "1040037  4409271026010  써스데이아일앤드      진케주얼  진케주얼  케주얼,구두,아동   의류패션팀    유니캐주얼   \n",
       "1040038  2116052008000      크리니크   수입종합화장품   화장품       명품잡화   잡화가용팀      화장품   \n",
       "\n",
       "         import_flg  tot_amt  dis_amt  net_amt  inst_mon  inst_fee  \n",
       "0                 1    90000     9000    81000         3         0  \n",
       "1                 1    39000     3900    35100         1         0  \n",
       "2                 1   175000    17500   157500         3         0  \n",
       "3                 1   455000    45500   409500         3         0  \n",
       "4                 0   100000    10000    90000         3         0  \n",
       "...             ...      ...      ...      ...       ...       ...  \n",
       "1040034           0    20000        0    20000         1         0  \n",
       "1040035           0    70000     3500    66500         1         0  \n",
       "1040036           0    39000        0    39000         1         0  \n",
       "1040037           0    34200        0    34200         1         0  \n",
       "1040038           1    86000     8600    77400         1         0  \n",
       "\n",
       "[1040039 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ac0b6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.goodcd.nunique()\n",
    "data.brd_nm.nunique()\n",
    "data.buyer_nm.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f02b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\AppData\\Local\\Temp\\ipykernel_2892\\3679107954.py:47: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#%%writefile word2vec_goodcd.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "train['goodcd']=train['goodcd'].astype('str')\n",
    "test['goodcd']=test['goodcd'].astype('str')\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'goodcd'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))  # 복원추출\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dffbe0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4400213022910',\n",
       " '4502161930200',\n",
       " '2116052008000',\n",
       " '4309200019900',\n",
       " '4309200019900',\n",
       " '4309200019900',\n",
       " '4134870003200',\n",
       " '4309200019900',\n",
       " '4502161930200',\n",
       " '4301000017000',\n",
       " '4400213022910',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '2116052008000',\n",
       " '4400213022910',\n",
       " '4301000017000',\n",
       " '4134870003200',\n",
       " '4522862046000',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4502161930200',\n",
       " '4134870003200',\n",
       " '4502161930200',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4400213022910',\n",
       " '4309200019900',\n",
       " '2116052008000',\n",
       " '4309200019900',\n",
       " '4502161930200',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '4301000017000',\n",
       " '4309200019900',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4309200019900',\n",
       " '4502161930200',\n",
       " '4309200019900',\n",
       " '4309200019900',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4134870003200',\n",
       " '4134870003200',\n",
       " '2116052008000',\n",
       " '4301000017000',\n",
       " '4400213022910',\n",
       " '4309200019900',\n",
       " '4522862046000',\n",
       " '4309200019900',\n",
       " '4301000017000',\n",
       " '4400213022910',\n",
       " '4301000017000',\n",
       " '2116052008000',\n",
       " '2116052008000',\n",
       " '4400213022910',\n",
       " '4502161930200',\n",
       " '4502161930200',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '4400213022910',\n",
       " '4134870003200',\n",
       " '4400213022910',\n",
       " '4134870003200',\n",
       " '4301000017000',\n",
       " '4301000017000',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4134870003200',\n",
       " '4134870003200',\n",
       " '4134870003200',\n",
       " '4309200019900',\n",
       " '4522862046000',\n",
       " '4309200019900',\n",
       " '4522862046000',\n",
       " '4301000017000',\n",
       " '4309200019900',\n",
       " '2116052008000',\n",
       " '4522862046000',\n",
       " '4309200019900',\n",
       " '4502161930200',\n",
       " '4400213022910',\n",
       " '4134870003200',\n",
       " '4301000017000',\n",
       " '4400213022910',\n",
       " '4309200019900',\n",
       " '4400213022910',\n",
       " '4522862046000',\n",
       " '4400213022910',\n",
       " '4400213022910',\n",
       " '4309200019900',\n",
       " '4400213022910',\n",
       " '4400213022910',\n",
       " '4400213022910',\n",
       " '2116052008000',\n",
       " '4522862046000',\n",
       " '4400213022910',\n",
       " '4309200019900',\n",
       " '4301000017000',\n",
       " '4502161930200',\n",
       " '4502161930200',\n",
       " '4502161930200',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4502161930200',\n",
       " '4134870003200',\n",
       " '4309200019900',\n",
       " '2116052008000',\n",
       " '4502161930200',\n",
       " '4522862046000',\n",
       " '2116052008000',\n",
       " '4134870003200',\n",
       " '4301000017000',\n",
       " '4400213022910',\n",
       " '4301000017000',\n",
       " '2116052008000',\n",
       " '4502161930200',\n",
       " '4309200019900',\n",
       " '4301000017000',\n",
       " '4301000017000',\n",
       " '4502161930200',\n",
       " '2116052008000',\n",
       " '4502161930200',\n",
       " '4134870003200',\n",
       " '2116052008000',\n",
       " '4301000017000',\n",
       " '4301000017000',\n",
       " '4309200019900',\n",
       " '4301000017000',\n",
       " '4309200019900',\n",
       " '4301000017000',\n",
       " '4134870003200',\n",
       " '4301000017000',\n",
       " '4522862046000',\n",
       " '4309200019900',\n",
       " '4522862046000',\n",
       " '4309200019900',\n",
       " '4309200019900']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1657258",
   "metadata": {},
   "source": [
    "## goodcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5dcc9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_goodcd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_goodcd.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "train['goodcd']=train['goodcd'].astype('str')\n",
    "test['goodcd']=test['goodcd'].astype('str')\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'goodcd'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))  # 복원추출\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                # 해당 단어가 있으면, max 뽑기.\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_goodcd = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_goodcd = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb6843bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_goodcd.py:48: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_goodcd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367788e0",
   "metadata": {},
   "source": [
    "## corner_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafb2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word2vec_corner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_corner.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'corner_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))  # 복원추출\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_corner = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_corner = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f826400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_corner.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_corner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e295cd",
   "metadata": {},
   "source": [
    "## brd_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f06d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word2vec_brd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_brd.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'brd_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 300 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_brd = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_brd = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e81ba23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_brd.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_brd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0533c",
   "metadata": {},
   "source": [
    "## pc_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3afab1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word2vec_pc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_pc.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'pc_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 50 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_pc = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_pc = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af136f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_pc.py:47: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_pc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4905b",
   "metadata": {},
   "source": [
    "## part_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51eb1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word2vec_part.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_part.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'part_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_part = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_part = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a82104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_part.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_part.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9b2f0",
   "metadata": {},
   "source": [
    "## customer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6539e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word2vec_customer_info.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_customer_info.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding = 'cp949')\n",
    "test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding = 'cp949')\n",
    "train['customer_info'] = train['brd_nm'].astype(str) + '_' + train['corner_nm'].astype(str) + '_' + train['pc_nm'].astype(str) + '_' + train['part_nm'].astype(str) + '_' + train['str_nm'].astype(str) + '_' + train['team_nm'].astype(str) + '_' + train['buyer_nm'].astype(str)\n",
    "test['customer_info'] = test['brd_nm'].astype(str) + '_' + test['corner_nm'].astype(str) + '_' + test['pc_nm'].astype(str) + '_' + test['part_nm'].astype(str) + '_' + test['str_nm'].astype(str) + '_' + test['team_nm'].astype(str) + '_' + test['buyer_nm'].astype(str)\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'customer_info'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_customer_info = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_customer_info = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ca080b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\KMU_2022\\머신러닝\\Kaggle\\머러뿌시조!\\준용\\notebook\\word2vec_customer_info.py:47: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_customer_info.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d06dab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21587"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['custid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b745211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>v001</th>\n",
       "      <th>v002</th>\n",
       "      <th>v003</th>\n",
       "      <th>v004</th>\n",
       "      <th>v005</th>\n",
       "      <th>v006</th>\n",
       "      <th>v007</th>\n",
       "      <th>v008</th>\n",
       "      <th>v009</th>\n",
       "      <th>...</th>\n",
       "      <th>v291</th>\n",
       "      <th>v292</th>\n",
       "      <th>v293</th>\n",
       "      <th>v294</th>\n",
       "      <th>v295</th>\n",
       "      <th>v296</th>\n",
       "      <th>v297</th>\n",
       "      <th>v298</th>\n",
       "      <th>v299</th>\n",
       "      <th>v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.260338</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.168903</td>\n",
       "      <td>0.237015</td>\n",
       "      <td>0.082573</td>\n",
       "      <td>0.113325</td>\n",
       "      <td>0.138312</td>\n",
       "      <td>0.078962</td>\n",
       "      <td>0.155916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025991</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.030848</td>\n",
       "      <td>-0.014227</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.018825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.084522</td>\n",
       "      <td>0.169908</td>\n",
       "      <td>0.307696</td>\n",
       "      <td>0.089508</td>\n",
       "      <td>0.151550</td>\n",
       "      <td>0.133955</td>\n",
       "      <td>0.152679</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>0.058381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065100</td>\n",
       "      <td>-0.061458</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>-0.005212</td>\n",
       "      <td>0.048923</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.059435</td>\n",
       "      <td>-0.026859</td>\n",
       "      <td>-0.007535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.131593</td>\n",
       "      <td>0.108714</td>\n",
       "      <td>0.194974</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>0.177746</td>\n",
       "      <td>0.160802</td>\n",
       "      <td>0.094236</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>0.243313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>-0.013183</td>\n",
       "      <td>0.032457</td>\n",
       "      <td>-0.035272</td>\n",
       "      <td>-0.025075</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.068903</td>\n",
       "      <td>-0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.074991</td>\n",
       "      <td>0.099207</td>\n",
       "      <td>-0.014526</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>0.242388</td>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056549</td>\n",
       "      <td>-0.091408</td>\n",
       "      <td>0.101024</td>\n",
       "      <td>0.066511</td>\n",
       "      <td>-0.019385</td>\n",
       "      <td>0.082454</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.055077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.135634</td>\n",
       "      <td>0.169908</td>\n",
       "      <td>0.307696</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.149320</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.121142</td>\n",
       "      <td>0.229865</td>\n",
       "      <td>0.205705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035143</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>0.035310</td>\n",
       "      <td>0.060995</td>\n",
       "      <td>-0.041829</td>\n",
       "      <td>0.036085</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>0.036049</td>\n",
       "      <td>-0.021792</td>\n",
       "      <td>-0.072991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>29995</td>\n",
       "      <td>0.227528</td>\n",
       "      <td>0.135506</td>\n",
       "      <td>0.243854</td>\n",
       "      <td>0.163731</td>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.257303</td>\n",
       "      <td>0.142808</td>\n",
       "      <td>0.218661</td>\n",
       "      <td>0.212525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044956</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>-0.010848</td>\n",
       "      <td>-0.038713</td>\n",
       "      <td>0.073433</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.047249</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.042151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>29996</td>\n",
       "      <td>0.099166</td>\n",
       "      <td>0.118184</td>\n",
       "      <td>0.178831</td>\n",
       "      <td>0.114362</td>\n",
       "      <td>0.103431</td>\n",
       "      <td>0.115233</td>\n",
       "      <td>0.101758</td>\n",
       "      <td>0.116661</td>\n",
       "      <td>0.204764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.081517</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>-0.106703</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>0.051520</td>\n",
       "      <td>0.011508</td>\n",
       "      <td>-0.005477</td>\n",
       "      <td>0.060011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>29997</td>\n",
       "      <td>0.197128</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.223647</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.237140</td>\n",
       "      <td>0.143406</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.115442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039707</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>-0.013323</td>\n",
       "      <td>-0.019012</td>\n",
       "      <td>-0.088614</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.040686</td>\n",
       "      <td>0.010941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>29998</td>\n",
       "      <td>0.125044</td>\n",
       "      <td>-0.020529</td>\n",
       "      <td>0.168903</td>\n",
       "      <td>0.237015</td>\n",
       "      <td>0.093186</td>\n",
       "      <td>0.205842</td>\n",
       "      <td>0.208659</td>\n",
       "      <td>0.111696</td>\n",
       "      <td>0.155916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>-0.002629</td>\n",
       "      <td>0.081760</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>-0.029690</td>\n",
       "      <td>-0.049138</td>\n",
       "      <td>-0.023227</td>\n",
       "      <td>-0.031093</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>29999</td>\n",
       "      <td>0.160734</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>-0.101442</td>\n",
       "      <td>0.109604</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>-0.092213</td>\n",
       "      <td>0.155830</td>\n",
       "      <td>0.205705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010273</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>-0.032402</td>\n",
       "      <td>-0.049155</td>\n",
       "      <td>-0.017527</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.057318</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>-0.023155</td>\n",
       "      <td>-0.056914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid      v001      v002      v003      v004      v005      v006  \\\n",
       "0           0  0.260338  0.186900  0.168903  0.237015  0.082573  0.113325   \n",
       "1           2  0.084522  0.169908  0.307696  0.089508  0.151550  0.133955   \n",
       "2           3  0.131593  0.108714  0.194974  0.115930  0.177746  0.160802   \n",
       "3           4  0.045032  0.074991  0.099207 -0.014526  0.101435  0.197985   \n",
       "4           5  0.135634  0.169908  0.307696  0.142087  0.149320  0.216524   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "21582   29995  0.227528  0.135506  0.243854  0.163731  0.165786  0.257303   \n",
       "21583   29996  0.099166  0.118184  0.178831  0.114362  0.103431  0.115233   \n",
       "21584   29997  0.197128  0.013331  0.223647  0.137698  0.237140  0.143406   \n",
       "21585   29998  0.125044 -0.020529  0.168903  0.237015  0.093186  0.205842   \n",
       "21586   29999  0.160734  0.009739 -0.017807 -0.101442  0.109604  0.117988   \n",
       "\n",
       "           v007      v008      v009  ...      v291      v292      v293  \\\n",
       "0      0.138312  0.078962  0.155916  ... -0.025991 -0.000108  0.000129   \n",
       "1      0.152679  0.070408  0.058381  ... -0.065100 -0.061458  0.035100   \n",
       "2      0.094236  0.251144  0.243313  ... -0.006330 -0.013183  0.032457   \n",
       "3      0.242388  0.013959  0.099826  ...  0.056549 -0.091408  0.101024   \n",
       "4      0.121142  0.229865  0.205705  ... -0.035143 -0.023590  0.035310   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21582  0.142808  0.218661  0.212525  ... -0.044956 -0.001147  0.028618   \n",
       "21583  0.101758  0.116661  0.204764  ... -0.004586  0.081517  0.034906   \n",
       "21584  0.168600  0.120567  0.115442  ... -0.039707  0.013380 -0.013323   \n",
       "21585  0.208659  0.111696  0.155916  ...  0.014070 -0.002629  0.081760   \n",
       "21586 -0.092213  0.155830  0.205705  ... -0.010273  0.090054 -0.032402   \n",
       "\n",
       "           v294      v295      v296      v297      v298      v299      v300  \n",
       "0      0.030848 -0.014227  0.024762  0.023667  0.003629  0.008228  0.018825  \n",
       "1      0.011991 -0.005212  0.048923  0.034615  0.059435 -0.026859 -0.007535  \n",
       "2     -0.035272 -0.025075  0.005341 -0.001299 -0.011132 -0.068903 -0.006227  \n",
       "3      0.066511 -0.019385  0.082454  0.040006  0.035480  0.005565  0.055077  \n",
       "4      0.060995 -0.041829  0.036085  0.060329  0.036049 -0.021792 -0.072991  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21582 -0.010848 -0.038713  0.073433 -0.000012  0.047249  0.015561  0.042151  \n",
       "21583  0.045792 -0.106703 -0.004214  0.051520  0.011508 -0.005477  0.060011  \n",
       "21584 -0.019012 -0.088614  0.000520  0.001611  0.015674  0.040686  0.010941  \n",
       "21585  0.003381 -0.029690 -0.049138 -0.023227 -0.031093 -0.021718  0.003012  \n",
       "21586 -0.049155 -0.017527  0.028854  0.057318  0.079272 -0.023155 -0.056914  \n",
       "\n",
       "[21587 rows x 301 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_goodcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7acf86f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>v001</th>\n",
       "      <th>v002</th>\n",
       "      <th>v003</th>\n",
       "      <th>v004</th>\n",
       "      <th>v005</th>\n",
       "      <th>v006</th>\n",
       "      <th>v007</th>\n",
       "      <th>v008</th>\n",
       "      <th>v009</th>\n",
       "      <th>...</th>\n",
       "      <th>v291</th>\n",
       "      <th>v292</th>\n",
       "      <th>v293</th>\n",
       "      <th>v294</th>\n",
       "      <th>v295</th>\n",
       "      <th>v296</th>\n",
       "      <th>v297</th>\n",
       "      <th>v298</th>\n",
       "      <th>v299</th>\n",
       "      <th>v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.056763</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.149943</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.059911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034173</td>\n",
       "      <td>-0.019983</td>\n",
       "      <td>-0.027080</td>\n",
       "      <td>-0.107699</td>\n",
       "      <td>-0.010033</td>\n",
       "      <td>-0.056021</td>\n",
       "      <td>-0.080666</td>\n",
       "      <td>0.151612</td>\n",
       "      <td>-0.083945</td>\n",
       "      <td>0.038805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.191025</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.233470</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.155885</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.016937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>-0.023767</td>\n",
       "      <td>-0.030189</td>\n",
       "      <td>-0.038454</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>-0.115047</td>\n",
       "      <td>0.042662</td>\n",
       "      <td>-0.039757</td>\n",
       "      <td>0.051180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.242797</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.165624</td>\n",
       "      <td>0.221735</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.105742</td>\n",
       "      <td>0.277712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029035</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>-0.014734</td>\n",
       "      <td>-0.065919</td>\n",
       "      <td>-0.046983</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>-0.039297</td>\n",
       "      <td>0.028133</td>\n",
       "      <td>-0.037585</td>\n",
       "      <td>-0.010387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.098454</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>-0.020919</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.126295</td>\n",
       "      <td>0.072836</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>-0.008190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.036180</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>-0.023432</td>\n",
       "      <td>0.036819</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.092997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.191025</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.233470</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.184796</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.170309</td>\n",
       "      <td>0.230378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>-0.024187</td>\n",
       "      <td>-0.079932</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>0.048558</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>0.004001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>29995</td>\n",
       "      <td>0.097922</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.178525</td>\n",
       "      <td>0.225589</td>\n",
       "      <td>0.184796</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.180570</td>\n",
       "      <td>0.116556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>-0.069201</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>-0.007725</td>\n",
       "      <td>-0.019666</td>\n",
       "      <td>0.062189</td>\n",
       "      <td>-0.078740</td>\n",
       "      <td>0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>29996</td>\n",
       "      <td>0.146767</td>\n",
       "      <td>0.174014</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.183424</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.184321</td>\n",
       "      <td>0.182815</td>\n",
       "      <td>0.068403</td>\n",
       "      <td>0.122801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>-0.005720</td>\n",
       "      <td>-0.071507</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.061454</td>\n",
       "      <td>0.081770</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>-0.030932</td>\n",
       "      <td>-0.050655</td>\n",
       "      <td>0.010133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>29997</td>\n",
       "      <td>0.105734</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.147673</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.170309</td>\n",
       "      <td>0.155350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>-0.030683</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.012866</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>0.010659</td>\n",
       "      <td>0.022828</td>\n",
       "      <td>-0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>29998</td>\n",
       "      <td>0.148536</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>-0.028444</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.104160</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>-0.008885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>-0.009168</td>\n",
       "      <td>-0.086843</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>-0.060501</td>\n",
       "      <td>-0.035885</td>\n",
       "      <td>-0.062862</td>\n",
       "      <td>0.014777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>29999</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>0.204751</td>\n",
       "      <td>0.050953</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.242940</td>\n",
       "      <td>0.068403</td>\n",
       "      <td>0.044445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056210</td>\n",
       "      <td>0.041944</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>-0.132657</td>\n",
       "      <td>-0.016899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid      v001      v002      v003      v004      v005      v006  \\\n",
       "0           0  0.056763  0.204751  0.149943  0.199081  0.008155  0.126571   \n",
       "1           2  0.191025  0.204751  0.233470  0.199081  0.041457  0.155885   \n",
       "2           3  0.164620  0.204751  0.242797  0.199081  0.165624  0.221735   \n",
       "3           4  0.098454  0.204751 -0.020919  0.199081  0.126295  0.072836   \n",
       "4           5  0.191025  0.204751  0.233470  0.199081  0.184796  0.204762   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "21582   29995  0.097922  0.204751  0.178525  0.225589  0.184796  0.204762   \n",
       "21583   29996  0.146767  0.174014  0.008641  0.183424  0.105979  0.184321   \n",
       "21584   29997  0.105734  0.204751  0.154300  0.199081  0.147673  0.086705   \n",
       "21585   29998  0.148536  0.204751 -0.028444  0.199081  0.104160  0.126571   \n",
       "21586   29999 -0.006907  0.204751  0.050953  0.199081  0.024893  0.155894   \n",
       "\n",
       "           v007      v008      v009  ...      v291      v292      v293  \\\n",
       "0      0.242940  0.013867  0.059911  ... -0.034173 -0.019983 -0.027080   \n",
       "1      0.242940  0.013867  0.016937  ...  0.009130  0.018982 -0.023767   \n",
       "2      0.242940  0.105742  0.277712  ...  0.029035  0.013338 -0.014734   \n",
       "3      0.242940  0.010505 -0.008190  ...  0.002299  0.127778  0.003761   \n",
       "4      0.242940  0.170309  0.230378  ...  0.002972  0.024026  0.009855   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21582  0.242940  0.180570  0.116556  ...  0.057885  0.021596 -0.069201   \n",
       "21583  0.182815  0.068403  0.122801  ...  0.010826 -0.005720 -0.071507   \n",
       "21584  0.242940  0.170309  0.155350  ...  0.035925  0.012268 -0.030683   \n",
       "21585  0.242940  0.045759 -0.008885  ...  0.025044  0.005114 -0.009168   \n",
       "21586  0.242940  0.068403  0.044445  ... -0.056210  0.041944 -0.001800   \n",
       "\n",
       "           v294      v295      v296      v297      v298      v299      v300  \n",
       "0     -0.107699 -0.010033 -0.056021 -0.080666  0.151612 -0.083945  0.038805  \n",
       "1     -0.030189 -0.038454  0.003262 -0.115047  0.042662 -0.039757  0.051180  \n",
       "2     -0.065919 -0.046983  0.005148 -0.039297  0.028133 -0.037585 -0.010387  \n",
       "3      0.036180  0.042810 -0.023432  0.036819 -0.006410  0.003924  0.092997  \n",
       "4     -0.024187 -0.079932  0.013594 -0.019925  0.048558 -0.027546  0.004001  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21582  0.019445  0.014048 -0.007725 -0.019666  0.062189 -0.078740  0.003395  \n",
       "21583  0.024601  0.061454  0.081770  0.018181 -0.030932 -0.050655  0.010133  \n",
       "21584  0.000322 -0.012866 -0.036804 -0.010471  0.010659  0.022828 -0.001081  \n",
       "21585 -0.086843 -0.013875  0.054422 -0.060501 -0.035885 -0.062862  0.014777  \n",
       "21586 -0.002566  0.096359  0.011204  0.010172  0.118980 -0.132657 -0.016899  \n",
       "\n",
       "[21587 rows x 301 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf93974",
   "metadata": {},
   "source": [
    "# Feature Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6b0ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_goodcd['custid']\n",
    "del X_test_goodcd['custid']\n",
    "del X_train_corner['custid']\n",
    "del X_test_corner['custid']\n",
    "del X_train_brd['custid']\n",
    "del X_test_brd['custid']\n",
    "del X_train_pc['custid']\n",
    "del X_test_pc['custid']\n",
    "del X_train_part['custid']\n",
    "del X_test_part['custid']\n",
    "del X_train_customer_info['custid']\n",
    "del X_test_customer_info['custid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "881a9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_goodcd.columns = X_train_corner.columns.map(lambda x : \"goodcd_\" + str(x))\n",
    "X_test_goodcd.columns = X_test_corner.columns.map(lambda x : \"goodcd_\" + str(x))\n",
    "X_train_corner.columns = X_train_corner.columns.map(lambda x : \"corner_\" + str(x))\n",
    "X_test_corner.columns = X_test_corner.columns.map(lambda x : \"corner_\" + str(x))\n",
    "X_train_brd.columns = X_train_brd.columns.map(lambda x : \"brd_\" + str(x))\n",
    "X_test_brd.columns = X_test_brd.columns.map(lambda x : \"brd_\" + str(x))\n",
    "X_train_pc.columns = X_train_pc.columns.map(lambda x : \"pc_\" + str(x))\n",
    "X_test_pc.columns = X_test_pc.columns.map(lambda x : \"pc_\" + str(x))\n",
    "X_train_part.columns = X_train_part.columns.map(lambda x : \"part_\" + str(x))\n",
    "X_test_part.columns = X_test_part.columns.map(lambda x : \"part_\" + str(x))\n",
    "X_train_customer_info.columns = X_train_customer_info.columns.map(lambda x : \"customer_info_\" + str(x))\n",
    "X_test_customer_info.columns = X_test_customer_info.columns.map(lambda x : \"customer_info_\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6292f5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodcd_v001</th>\n",
       "      <th>goodcd_v002</th>\n",
       "      <th>goodcd_v003</th>\n",
       "      <th>goodcd_v004</th>\n",
       "      <th>goodcd_v005</th>\n",
       "      <th>goodcd_v006</th>\n",
       "      <th>goodcd_v007</th>\n",
       "      <th>goodcd_v008</th>\n",
       "      <th>goodcd_v009</th>\n",
       "      <th>goodcd_v010</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_info_v291</th>\n",
       "      <th>customer_info_v292</th>\n",
       "      <th>customer_info_v293</th>\n",
       "      <th>customer_info_v294</th>\n",
       "      <th>customer_info_v295</th>\n",
       "      <th>customer_info_v296</th>\n",
       "      <th>customer_info_v297</th>\n",
       "      <th>customer_info_v298</th>\n",
       "      <th>customer_info_v299</th>\n",
       "      <th>customer_info_v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129422</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.307696</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.165786</td>\n",
       "      <td>0.224780</td>\n",
       "      <td>0.197644</td>\n",
       "      <td>0.220256</td>\n",
       "      <td>0.222983</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037652</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>-0.020826</td>\n",
       "      <td>-0.055512</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>-0.006132</td>\n",
       "      <td>0.055545</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>-0.011972</td>\n",
       "      <td>0.072295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171728</td>\n",
       "      <td>0.141858</td>\n",
       "      <td>0.242991</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>0.142499</td>\n",
       "      <td>0.235643</td>\n",
       "      <td>0.220895</td>\n",
       "      <td>0.165577</td>\n",
       "      <td>0.207531</td>\n",
       "      <td>0.288024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.060104</td>\n",
       "      <td>-0.038520</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>-0.016071</td>\n",
       "      <td>0.006630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.123039</td>\n",
       "      <td>0.083569</td>\n",
       "      <td>0.081921</td>\n",
       "      <td>0.174803</td>\n",
       "      <td>0.178339</td>\n",
       "      <td>0.205842</td>\n",
       "      <td>0.128738</td>\n",
       "      <td>0.217661</td>\n",
       "      <td>0.247399</td>\n",
       "      <td>0.194495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>-0.091674</td>\n",
       "      <td>-0.007643</td>\n",
       "      <td>-0.009296</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>0.048004</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.034725</td>\n",
       "      <td>0.027391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099166</td>\n",
       "      <td>-0.214820</td>\n",
       "      <td>-0.175486</td>\n",
       "      <td>0.071684</td>\n",
       "      <td>0.081226</td>\n",
       "      <td>-0.032194</td>\n",
       "      <td>-0.064322</td>\n",
       "      <td>0.060789</td>\n",
       "      <td>0.057255</td>\n",
       "      <td>-0.033473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.127233</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>-0.009906</td>\n",
       "      <td>0.022087</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.092757</td>\n",
       "      <td>-0.097661</td>\n",
       "      <td>-0.106951</td>\n",
       "      <td>0.113660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062828</td>\n",
       "      <td>-0.007628</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.188506</td>\n",
       "      <td>0.089032</td>\n",
       "      <td>0.178485</td>\n",
       "      <td>0.138662</td>\n",
       "      <td>0.158986</td>\n",
       "      <td>0.054364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>-0.056631</td>\n",
       "      <td>0.014909</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>-0.015764</td>\n",
       "      <td>-0.047946</td>\n",
       "      <td>-0.028684</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.040479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.061392</td>\n",
       "      <td>-0.059110</td>\n",
       "      <td>0.145619</td>\n",
       "      <td>0.136968</td>\n",
       "      <td>-0.039073</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.054909</td>\n",
       "      <td>0.155830</td>\n",
       "      <td>0.205705</td>\n",
       "      <td>0.064942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010387</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>-0.155586</td>\n",
       "      <td>0.047136</td>\n",
       "      <td>-0.024409</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.092307</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>-0.008026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>-0.034577</td>\n",
       "      <td>-0.252133</td>\n",
       "      <td>-0.117986</td>\n",
       "      <td>-0.062228</td>\n",
       "      <td>0.067351</td>\n",
       "      <td>-0.176212</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>-0.002536</td>\n",
       "      <td>0.058381</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>-0.118620</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>-0.051260</td>\n",
       "      <td>-0.110725</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.094125</td>\n",
       "      <td>-0.016829</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.060730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>-0.051799</td>\n",
       "      <td>-0.047219</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>-0.110591</td>\n",
       "      <td>0.082573</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>-0.117187</td>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.155342</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>-0.043835</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>-0.066196</td>\n",
       "      <td>0.069820</td>\n",
       "      <td>-0.024159</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.060873</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.137935</td>\n",
       "      <td>0.093982</td>\n",
       "      <td>0.035913</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.069784</td>\n",
       "      <td>0.093307</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.047154</td>\n",
       "      <td>0.063743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.077669</td>\n",
       "      <td>-0.086390</td>\n",
       "      <td>-0.069017</td>\n",
       "      <td>0.078894</td>\n",
       "      <td>0.092026</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>-0.046485</td>\n",
       "      <td>0.066622</td>\n",
       "      <td>0.096271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.020046</td>\n",
       "      <td>-0.056855</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>0.041456</td>\n",
       "      <td>0.067351</td>\n",
       "      <td>0.119503</td>\n",
       "      <td>0.176470</td>\n",
       "      <td>0.025911</td>\n",
       "      <td>0.064339</td>\n",
       "      <td>0.158662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.062050</td>\n",
       "      <td>-0.125082</td>\n",
       "      <td>0.034207</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>-0.025108</td>\n",
       "      <td>0.072957</td>\n",
       "      <td>0.106415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 2250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       goodcd_v001  goodcd_v002  goodcd_v003  goodcd_v004  goodcd_v005  \\\n",
       "0         0.129422     0.186900     0.307696     0.103418     0.165786   \n",
       "1         0.171728     0.141858     0.242991     0.224061     0.142499   \n",
       "2         0.123039     0.083569     0.081921     0.174803     0.178339   \n",
       "3         0.099166    -0.214820    -0.175486     0.071684     0.081226   \n",
       "4         0.062828    -0.007628     0.018975     0.037392     0.188506   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "14375     0.061392    -0.059110     0.145619     0.136968    -0.039073   \n",
       "14376    -0.034577    -0.252133    -0.117986    -0.062228     0.067351   \n",
       "14377    -0.051799    -0.047219     0.081804    -0.110591     0.082573   \n",
       "14378     0.137935     0.093982     0.035913     0.101195     0.080409   \n",
       "14379     0.020046    -0.056855    -0.001671     0.041456     0.067351   \n",
       "\n",
       "       goodcd_v006  goodcd_v007  goodcd_v008  goodcd_v009  goodcd_v010  ...  \\\n",
       "0         0.224780     0.197644     0.220256     0.222983     0.198732  ...   \n",
       "1         0.235643     0.220895     0.165577     0.207531     0.288024  ...   \n",
       "2         0.205842     0.128738     0.217661     0.247399     0.194495  ...   \n",
       "3        -0.032194    -0.064322     0.060789     0.057255    -0.033473  ...   \n",
       "4         0.089032     0.178485     0.138662     0.158986     0.054364  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "14375     0.172800     0.054909     0.155830     0.205705     0.064942  ...   \n",
       "14376    -0.176212     0.031558    -0.002536     0.058381     0.010223  ...   \n",
       "14377     0.006183    -0.117187     0.018908     0.155342     0.100011  ...   \n",
       "14378     0.069784     0.093307     0.003883     0.047154     0.063743  ...   \n",
       "14379     0.119503     0.176470     0.025911     0.064339     0.158662  ...   \n",
       "\n",
       "       customer_info_v291  customer_info_v292  customer_info_v293  \\\n",
       "0               -0.037652           -0.001466           -0.020826   \n",
       "1               -0.029072            0.011011           -0.014196   \n",
       "2                0.011028           -0.091674           -0.007643   \n",
       "3               -0.002563           -0.127233           -0.027754   \n",
       "4                0.025815           -0.056631            0.014909   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.010387            0.102729           -0.155586   \n",
       "14376            0.108780           -0.118620           -0.002562   \n",
       "14377            0.000037            0.100021           -0.043835   \n",
       "14378            0.001007           -0.077669           -0.086390   \n",
       "14379            0.003847            0.001377            0.062050   \n",
       "\n",
       "       customer_info_v294  customer_info_v295  customer_info_v296  \\\n",
       "0               -0.055512            0.017100           -0.006132   \n",
       "1               -0.060104           -0.038520            0.017734   \n",
       "2               -0.009296            0.020878           -0.008030   \n",
       "3               -0.009906            0.022087            0.042219   \n",
       "4                0.003187           -0.015764           -0.047946   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.047136           -0.024409            0.066448   \n",
       "14376           -0.051260           -0.110725            0.010442   \n",
       "14377            0.016731           -0.066196            0.069820   \n",
       "14378           -0.069017            0.078894            0.092026   \n",
       "14379           -0.125082            0.034207            0.005540   \n",
       "\n",
       "       customer_info_v297  customer_info_v298  customer_info_v299  \\\n",
       "0                0.055545            0.009020           -0.011972   \n",
       "1                0.006911            0.016092           -0.016071   \n",
       "2                0.048004           -0.000222           -0.034725   \n",
       "3                0.092757           -0.097661           -0.106951   \n",
       "4               -0.028684            0.035731            0.004185   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.092307            0.037059            0.009746   \n",
       "14376            0.094125           -0.016829            0.038454   \n",
       "14377           -0.024159            0.078777            0.060873   \n",
       "14378            0.018246           -0.046485            0.066622   \n",
       "14379            0.014995           -0.025108            0.072957   \n",
       "\n",
       "       customer_info_v300  \n",
       "0                0.072295  \n",
       "1                0.006630  \n",
       "2                0.027391  \n",
       "3                0.113660  \n",
       "4                0.040479  \n",
       "...                   ...  \n",
       "14375           -0.008026  \n",
       "14376            0.060730  \n",
       "14377            0.000105  \n",
       "14378            0.096271  \n",
       "14379            0.106415  \n",
       "\n",
       "[14380 rows x 2250 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features_train = pd.concat([X_train_goodcd,X_train_corner, X_train_brd, X_train_pc, X_train_part, X_train_customer_info], axis=1) ; w2v_features_train\n",
    "w2v_features_test = pd.concat([X_test_goodcd,X_test_corner, X_test_brd, X_test_pc, X_test_part, X_test_customer_info], axis=1) ; w2v_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d379abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_features_train.to_csv('choi_w2v_features_train.csv', index=False)\n",
    "w2v_features_test.to_csv('choi_w2v_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf06d13",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
