{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfa5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b019dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('X_train.csv', encoding = 'cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding = 'cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding = 'cp949')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee14bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1657258",
   "metadata": {},
   "source": [
    "## corner_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d3073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_corner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_corner.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'corner_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))  # 복원추출\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_corner = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_corner = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec42b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\Desktop\\머신러닝\\kml2022s\\word2vec_corner.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_corner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e295cd",
   "metadata": {},
   "source": [
    "## brd_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f62aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_brd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_brd.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'brd_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 300 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_brd = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_brd = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4113ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\Desktop\\머신러닝\\kml2022s\\word2vec_brd.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_brd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0533c",
   "metadata": {},
   "source": [
    "## pc_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c5c5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_pc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_pc.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'pc_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 50 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_pc = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_pc = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c3fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\Desktop\\머신러닝\\kml2022s\\word2vec_pc.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_pc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4905b",
   "metadata": {},
   "source": [
    "## part_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51eb1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_part.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_part.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'part_nm'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_part = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_part = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac22b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\Desktop\\머신러닝\\kml2022s\\word2vec_part.py:46: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_part.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9b2f0",
   "metadata": {},
   "source": [
    "## customer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6539e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word2vec_customer_info.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word2vec_customer_info.py\n",
    "\n",
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "### Read data\n",
    "train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "train['customer_info'] = train['brd_nm'].astype(str) + '_' + train['corner_nm'].astype(str) + '_' + train['pc_nm'].astype(str) + '_' + train['part_nm'].astype(str) + '_' + train['str_nm'].astype(str) + '_' + train['team_nm'].astype(str) + '_' + train['buyer_nm'].astype(str)\n",
    "test['customer_info'] = test['brd_nm'].astype(str) + '_' + test['corner_nm'].astype(str) + '_' + test['pc_nm'].astype(str) + '_' + test['part_nm'].astype(str) + '_' + test['str_nm'].astype(str) + '_' + test['team_nm'].astype(str) + '_' + test['buyer_nm'].astype(str)\n",
    "\n",
    "### Make corpus\n",
    "p_level = 'customer_info'  # 상품 분류 수준\n",
    "\n",
    "# W2V 학습데이터가 부족하여 구매한 상품 목록으로부터 n배 oversampling을 수행\n",
    "def oversample(x, n, seed=0):\n",
    "    if n == 0:\n",
    "        return list(x)\n",
    "    uw = np.unique(x)\n",
    "    bs = np.array([])\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n):\n",
    "        bs = np.append(bs, np.random.choice(uw, len(uw), replace=True))\n",
    "    return list(bs)\n",
    "\n",
    "train_corpus = list(train.groupby('custid')[p_level].agg(oversample, 20))\n",
    "test_corpus = list(test.groupby('custid')[p_level].agg(oversample, 20))\n",
    "\n",
    "\n",
    "### Training the Word2Vec model\n",
    "num_features = 100 # 단어 벡터 차원 수\n",
    "min_word_count = 1 # 최소 단어 수\n",
    "context = 5 # 학습 윈도우(인접한 단어 리스트) 크기\n",
    "\n",
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 학습\n",
    "w2v = word2vec.Word2Vec(train_corpus, \n",
    "                        vector_size=num_features, \n",
    "                        min_count=min_word_count,\n",
    "                        window=context,\n",
    "                        seed=0, workers=1)\n",
    "# 필요없는 메모리 unload\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "\n",
    "### Make features\n",
    "# 구매상품에 해당하는 벡터의 평균/최소/최대 벡터를 feature로 만드는 전처리기\n",
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = num_features\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.hstack([\n",
    "                np.max([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.min([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0),                \n",
    "                #np.std([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)                \n",
    "            ]) \n",
    "            for words in X\n",
    "        ]) \n",
    "\n",
    "# W2V 기반 feature 생성\n",
    "train_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).fit(train_corpus).transform(train_corpus))\n",
    "test_features = pd.DataFrame(EmbeddingVectorizer(w2v.wv).transform(test_corpus))\n",
    "\n",
    "train_features.columns = ['v'+f'{c+1:03d}' for c in train_features.columns]\n",
    "test_features.columns = ['v'+f'{c+1:03d}' for c in test_features.columns]\n",
    "\n",
    "# 학습용과 제출용 데이터로 분리\n",
    "X_train_customer_info = pd.concat([pd.DataFrame({'custid': np.sort(train['custid'].unique())}), train_features], axis=1)#.to_csv('X_train_buyer.csv', index=False)\n",
    "X_test_customer_info = pd.concat([pd.DataFrame({'custid': np.sort(test['custid'].unique())}), test_features], axis=1)#.to_csv('X_test_buyer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f51789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hwangtaegyun\\Desktop\\머신러닝\\kml2022s\\word2vec_customer_info.py:47: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "%run word2vec_customer_info.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad7fecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21587"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['custid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbd3f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custid</th>\n",
       "      <th>v001</th>\n",
       "      <th>v002</th>\n",
       "      <th>v003</th>\n",
       "      <th>v004</th>\n",
       "      <th>v005</th>\n",
       "      <th>v006</th>\n",
       "      <th>v007</th>\n",
       "      <th>v008</th>\n",
       "      <th>v009</th>\n",
       "      <th>...</th>\n",
       "      <th>v291</th>\n",
       "      <th>v292</th>\n",
       "      <th>v293</th>\n",
       "      <th>v294</th>\n",
       "      <th>v295</th>\n",
       "      <th>v296</th>\n",
       "      <th>v297</th>\n",
       "      <th>v298</th>\n",
       "      <th>v299</th>\n",
       "      <th>v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.056887</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.149636</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.061884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033926</td>\n",
       "      <td>-0.020497</td>\n",
       "      <td>-0.026160</td>\n",
       "      <td>-0.110019</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>-0.055391</td>\n",
       "      <td>-0.079253</td>\n",
       "      <td>0.150992</td>\n",
       "      <td>-0.084426</td>\n",
       "      <td>0.038927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.191458</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.233395</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.040383</td>\n",
       "      <td>0.156419</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>-0.023277</td>\n",
       "      <td>-0.031402</td>\n",
       "      <td>-0.038590</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>-0.114791</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>-0.039728</td>\n",
       "      <td>0.051065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.165631</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.242314</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.168026</td>\n",
       "      <td>0.224666</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.105736</td>\n",
       "      <td>0.279617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028608</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>-0.014507</td>\n",
       "      <td>-0.065977</td>\n",
       "      <td>-0.047070</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>-0.039338</td>\n",
       "      <td>0.028312</td>\n",
       "      <td>-0.037684</td>\n",
       "      <td>-0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.101547</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>-0.021308</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.126062</td>\n",
       "      <td>0.071227</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>-0.007040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.128726</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>0.042530</td>\n",
       "      <td>-0.022697</td>\n",
       "      <td>0.036814</td>\n",
       "      <td>-0.005544</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.093528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.191458</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.233395</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.204068</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.229982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>-0.024842</td>\n",
       "      <td>-0.080310</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>-0.027887</td>\n",
       "      <td>0.004168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>29995</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.178591</td>\n",
       "      <td>0.226137</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.204068</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.180266</td>\n",
       "      <td>0.116643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057960</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>-0.068603</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>-0.018961</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>-0.078828</td>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>29996</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>0.172708</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.184141</td>\n",
       "      <td>0.108564</td>\n",
       "      <td>0.185031</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.069782</td>\n",
       "      <td>0.122507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>-0.071838</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.061403</td>\n",
       "      <td>0.081722</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>-0.031068</td>\n",
       "      <td>-0.051589</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>29997</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.155505</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.149265</td>\n",
       "      <td>0.086596</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.153283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035744</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>-0.030162</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.013196</td>\n",
       "      <td>-0.036134</td>\n",
       "      <td>-0.010156</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>-0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>29998</td>\n",
       "      <td>0.148576</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>-0.027938</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.106893</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.045363</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>-0.008971</td>\n",
       "      <td>-0.086903</td>\n",
       "      <td>-0.014310</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>-0.059484</td>\n",
       "      <td>-0.036537</td>\n",
       "      <td>-0.063727</td>\n",
       "      <td>0.015486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>29999</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.026324</td>\n",
       "      <td>0.154370</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.069782</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055858</td>\n",
       "      <td>0.042386</td>\n",
       "      <td>-0.001359</td>\n",
       "      <td>-0.004991</td>\n",
       "      <td>0.096091</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.119763</td>\n",
       "      <td>-0.133195</td>\n",
       "      <td>-0.018224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21587 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       custid      v001      v002      v003      v004      v005      v006  \\\n",
       "0           0  0.056887  0.204296  0.149636  0.197877  0.011895  0.125749   \n",
       "1           2  0.191458  0.204296  0.233395  0.197877  0.040383  0.156419   \n",
       "2           3  0.165631  0.204296  0.242314  0.197877  0.168026  0.224666   \n",
       "3           4  0.101547  0.204296 -0.021308  0.197877  0.126062  0.071227   \n",
       "4           5  0.191458  0.204296  0.233395  0.197877  0.186105  0.204068   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "21582   29995  0.096043  0.204296  0.178591  0.226137  0.186105  0.204068   \n",
       "21583   29996  0.144552  0.172708  0.010097  0.184141  0.108564  0.185031   \n",
       "21584   29997  0.106106  0.204296  0.155505  0.197877  0.149265  0.086596   \n",
       "21585   29998  0.148576  0.204296 -0.027938  0.197877  0.106893  0.125749   \n",
       "21586   29999 -0.008100  0.204296  0.051525  0.197877  0.026324  0.154370   \n",
       "\n",
       "           v007      v008      v009  ...      v291      v292      v293  \\\n",
       "0      0.243023  0.012182  0.061884  ... -0.033926 -0.020497 -0.026160   \n",
       "1      0.243023  0.012182  0.016669  ...  0.009210  0.018467 -0.023277   \n",
       "2      0.243023  0.105736  0.279617  ...  0.028608  0.013825 -0.014507   \n",
       "3      0.243023  0.012068 -0.007040  ...  0.002926  0.128726  0.003520   \n",
       "4      0.243023  0.169524  0.229982  ...  0.002585  0.024336  0.010207   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21582  0.243023  0.180266  0.116643  ...  0.057960  0.021938 -0.068603   \n",
       "21583  0.184655  0.069782  0.122507  ...  0.011448 -0.005515 -0.071838   \n",
       "21584  0.243023  0.169524  0.153283  ...  0.035744  0.012318 -0.030162   \n",
       "21585  0.243023  0.045363 -0.009854  ...  0.025380  0.005048 -0.008971   \n",
       "21586  0.243023  0.069782  0.044865  ... -0.055858  0.042386 -0.001359   \n",
       "\n",
       "           v294      v295      v296      v297      v298      v299      v300  \n",
       "0     -0.110019 -0.010025 -0.055391 -0.079253  0.150992 -0.084426  0.038927  \n",
       "1     -0.031402 -0.038590  0.004241 -0.114791  0.043011 -0.039728  0.051065  \n",
       "2     -0.065977 -0.047070  0.005692 -0.039338  0.028312 -0.037684 -0.010549  \n",
       "3      0.034850  0.042530 -0.022697  0.036814 -0.005544  0.004125  0.093528  \n",
       "4     -0.024842 -0.080310  0.013839 -0.019896  0.048257 -0.027887  0.004168  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "21582  0.019180  0.013408 -0.006916 -0.018961  0.062378 -0.078828  0.003307  \n",
       "21583  0.024338  0.061403  0.081722  0.018449 -0.031068 -0.051589  0.008815  \n",
       "21584 -0.000588 -0.013196 -0.036134 -0.010156  0.011357  0.023214 -0.000401  \n",
       "21585 -0.086903 -0.014310  0.053836 -0.059484 -0.036537 -0.063727  0.015486  \n",
       "21586 -0.004991  0.096091  0.012899  0.011657  0.119763 -0.133195 -0.018224  \n",
       "\n",
       "[21587 rows x 301 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf93974",
   "metadata": {},
   "source": [
    "# Feature Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3352d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_corner['custid']\n",
    "del X_test_corner['custid']\n",
    "del X_train_brd['custid']\n",
    "del X_test_brd['custid']\n",
    "del X_train_pc['custid']\n",
    "del X_test_pc['custid']\n",
    "del X_train_part['custid']\n",
    "del X_test_part['custid']\n",
    "del X_train_customer_info['custid']\n",
    "del X_test_customer_info['custid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1043ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_corner.columns = X_train_corner.columns.map(lambda x : \"corner_\" + str(x))\n",
    "X_test_corner.columns = X_test_corner.columns.map(lambda x : \"corner_\" + str(x))\n",
    "X_train_brd.columns = X_train_brd.columns.map(lambda x : \"brd_\" + str(x))\n",
    "X_test_brd.columns = X_test_brd.columns.map(lambda x : \"brd_\" + str(x))\n",
    "X_train_pc.columns = X_train_pc.columns.map(lambda x : \"pc_\" + str(x))\n",
    "X_test_pc.columns = X_test_pc.columns.map(lambda x : \"pc_\" + str(x))\n",
    "X_train_part.columns = X_train_part.columns.map(lambda x : \"part_\" + str(x))\n",
    "X_test_part.columns = X_test_part.columns.map(lambda x : \"part_\" + str(x))\n",
    "X_train_customer_info.columns = X_train_customer_info.columns.map(lambda x : \"customer_info_\" + str(x))\n",
    "X_test_customer_info.columns = X_test_customer_info.columns.map(lambda x : \"customer_info_\" + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76207352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corner_v001</th>\n",
       "      <th>corner_v002</th>\n",
       "      <th>corner_v003</th>\n",
       "      <th>corner_v004</th>\n",
       "      <th>corner_v005</th>\n",
       "      <th>corner_v006</th>\n",
       "      <th>corner_v007</th>\n",
       "      <th>corner_v008</th>\n",
       "      <th>corner_v009</th>\n",
       "      <th>corner_v010</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_info_v291</th>\n",
       "      <th>customer_info_v292</th>\n",
       "      <th>customer_info_v293</th>\n",
       "      <th>customer_info_v294</th>\n",
       "      <th>customer_info_v295</th>\n",
       "      <th>customer_info_v296</th>\n",
       "      <th>customer_info_v297</th>\n",
       "      <th>customer_info_v298</th>\n",
       "      <th>customer_info_v299</th>\n",
       "      <th>customer_info_v300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168851</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.299397</td>\n",
       "      <td>0.216977</td>\n",
       "      <td>0.138331</td>\n",
       "      <td>0.224666</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.180266</td>\n",
       "      <td>0.180750</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037653</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>-0.020813</td>\n",
       "      <td>-0.055448</td>\n",
       "      <td>0.017109</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>0.055517</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>-0.012030</td>\n",
       "      <td>0.072338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146209</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.242314</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.204068</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.180266</td>\n",
       "      <td>0.163607</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029030</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.060091</td>\n",
       "      <td>-0.038459</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>-0.016071</td>\n",
       "      <td>0.006643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137170</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.132994</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.188748</td>\n",
       "      <td>0.109339</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.196390</td>\n",
       "      <td>0.133698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>-0.091655</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>-0.009337</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>-0.034780</td>\n",
       "      <td>0.027391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.039974</td>\n",
       "      <td>-0.054913</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.184141</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>-0.082661</td>\n",
       "      <td>0.039018</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>-0.036910</td>\n",
       "      <td>-0.126528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>-0.127154</td>\n",
       "      <td>-0.027601</td>\n",
       "      <td>-0.010497</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.093091</td>\n",
       "      <td>-0.098226</td>\n",
       "      <td>-0.106143</td>\n",
       "      <td>0.113597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.047150</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>-0.008322</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.042577</td>\n",
       "      <td>-0.003618</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>0.088701</td>\n",
       "      <td>0.117397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>-0.056540</td>\n",
       "      <td>0.014996</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.047980</td>\n",
       "      <td>-0.028539</td>\n",
       "      <td>0.035711</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.040221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.221683</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>-0.003618</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>0.183859</td>\n",
       "      <td>0.148194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.102751</td>\n",
       "      <td>-0.155536</td>\n",
       "      <td>0.047139</td>\n",
       "      <td>-0.024476</td>\n",
       "      <td>0.066521</td>\n",
       "      <td>0.092263</td>\n",
       "      <td>0.037041</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>-0.007837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>-0.047150</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>-0.122241</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>-0.040419</td>\n",
       "      <td>-0.003618</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>-0.036919</td>\n",
       "      <td>-0.134704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>-0.118788</td>\n",
       "      <td>-0.002599</td>\n",
       "      <td>-0.051196</td>\n",
       "      <td>-0.111106</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.094173</td>\n",
       "      <td>-0.016554</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.060349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>-0.047150</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.109177</td>\n",
       "      <td>0.226137</td>\n",
       "      <td>-0.022702</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>-0.014092</td>\n",
       "      <td>0.029511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>-0.043911</td>\n",
       "      <td>0.016829</td>\n",
       "      <td>-0.066134</td>\n",
       "      <td>0.069977</td>\n",
       "      <td>-0.024249</td>\n",
       "      <td>0.078696</td>\n",
       "      <td>0.060989</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.144552</td>\n",
       "      <td>0.172708</td>\n",
       "      <td>0.072305</td>\n",
       "      <td>0.135013</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.098543</td>\n",
       "      <td>0.146069</td>\n",
       "      <td>0.203590</td>\n",
       "      <td>0.140965</td>\n",
       "      <td>0.148194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.077672</td>\n",
       "      <td>-0.086397</td>\n",
       "      <td>-0.069124</td>\n",
       "      <td>0.078886</td>\n",
       "      <td>0.092147</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>-0.046397</td>\n",
       "      <td>0.066673</td>\n",
       "      <td>0.096268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>-0.037630</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>0.057388</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.095841</td>\n",
       "      <td>-0.016821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>-0.125218</td>\n",
       "      <td>0.034228</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>-0.024855</td>\n",
       "      <td>0.072710</td>\n",
       "      <td>0.106232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 1950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       corner_v001  corner_v002  corner_v003  corner_v004  corner_v005  \\\n",
       "0         0.168851     0.204296     0.299397     0.216977     0.138331   \n",
       "1         0.146209     0.204296     0.242314     0.197877     0.186105   \n",
       "2         0.137170     0.204296     0.132994     0.197877     0.188748   \n",
       "3        -0.039974    -0.054913     0.010097     0.184141     0.083852   \n",
       "4        -0.047150     0.204296    -0.008322     0.197877     0.042577   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "14375     0.221683     0.204296     0.106887     0.197877     0.005162   \n",
       "14376    -0.047150     0.204296    -0.122241     0.197877    -0.040419   \n",
       "14377    -0.047150     0.204296     0.109177     0.226137    -0.022702   \n",
       "14378     0.144552     0.172708     0.072305     0.135013     0.014147   \n",
       "14379     0.005652     0.204296    -0.037630     0.197877    -0.006947   \n",
       "\n",
       "       corner_v006  corner_v007  corner_v008  corner_v009  corner_v010  ...  \\\n",
       "0         0.224666     0.243023     0.180266     0.180750     0.185686  ...   \n",
       "1         0.204068     0.243023     0.180266     0.163607     0.103400  ...   \n",
       "2         0.109339     0.243023     0.182364     0.196390     0.133698  ...   \n",
       "3        -0.082661     0.039018    -0.000735    -0.036910    -0.126528  ...   \n",
       "4        -0.003618     0.243023     0.012068     0.088701     0.117397  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "14375    -0.003618     0.243023     0.012068     0.183859     0.148194  ...   \n",
       "14376    -0.003618     0.243023     0.012068    -0.036919    -0.134704  ...   \n",
       "14377     0.048333     0.243023     0.076473    -0.014092     0.029511  ...   \n",
       "14378     0.098543     0.146069     0.203590     0.140965     0.148194  ...   \n",
       "14379     0.057388     0.243023     0.024456     0.095841    -0.016821  ...   \n",
       "\n",
       "       customer_info_v291  customer_info_v292  customer_info_v293  \\\n",
       "0               -0.037653           -0.001484           -0.020813   \n",
       "1               -0.029030            0.010975           -0.014133   \n",
       "2                0.011038           -0.091655           -0.007590   \n",
       "3               -0.003080           -0.127154           -0.027601   \n",
       "4                0.025820           -0.056540            0.014996   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.010272            0.102751           -0.155536   \n",
       "14376            0.108693           -0.118788           -0.002599   \n",
       "14377            0.000036            0.099930           -0.043911   \n",
       "14378            0.001012           -0.077672           -0.086397   \n",
       "14379            0.003794            0.001473            0.062132   \n",
       "\n",
       "       customer_info_v294  customer_info_v295  customer_info_v296  \\\n",
       "0               -0.055448            0.017109           -0.006111   \n",
       "1               -0.060091           -0.038459            0.017820   \n",
       "2               -0.009337            0.020900           -0.007950   \n",
       "3               -0.010497            0.022230            0.042322   \n",
       "4                0.003111           -0.015839           -0.047980   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.047139           -0.024476            0.066521   \n",
       "14376           -0.051196           -0.111106            0.010698   \n",
       "14377            0.016829           -0.066134            0.069977   \n",
       "14378           -0.069124            0.078886            0.092147   \n",
       "14379           -0.125218            0.034228            0.005444   \n",
       "\n",
       "       customer_info_v297  customer_info_v298  customer_info_v299  \\\n",
       "0                0.055517            0.009039           -0.012030   \n",
       "1                0.006929            0.016060           -0.016071   \n",
       "2                0.047982           -0.000275           -0.034780   \n",
       "3                0.093091           -0.098226           -0.106143   \n",
       "4               -0.028539            0.035711            0.004489   \n",
       "...                   ...                 ...                 ...   \n",
       "14375            0.092263            0.037041            0.009806   \n",
       "14376            0.094173           -0.016554            0.038679   \n",
       "14377           -0.024249            0.078696            0.060989   \n",
       "14378            0.018202           -0.046397            0.066673   \n",
       "14379            0.015023           -0.024855            0.072710   \n",
       "\n",
       "       customer_info_v300  \n",
       "0                0.072338  \n",
       "1                0.006643  \n",
       "2                0.027391  \n",
       "3                0.113597  \n",
       "4                0.040221  \n",
       "...                   ...  \n",
       "14375           -0.007837  \n",
       "14376            0.060349  \n",
       "14377            0.000194  \n",
       "14378            0.096268  \n",
       "14379            0.106232  \n",
       "\n",
       "[14380 rows x 1950 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_features_train = pd.concat([X_train_corner, X_train_brd, X_train_pc, X_train_part, X_train_customer_info], axis=1) ; w2v_features_train\n",
    "w2v_features_test = pd.concat([X_test_corner, X_test_brd, X_test_pc, X_test_part, X_test_customer_info], axis=1) ; w2v_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb3ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_features_train.to_csv('hwang_w2v_features_train.csv', index=False)\n",
    "w2v_features_test.to_csv('hwang_w2v_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90870e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92fc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
