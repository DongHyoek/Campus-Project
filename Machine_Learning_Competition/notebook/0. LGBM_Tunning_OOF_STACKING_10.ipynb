{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08505bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "# import klib\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer  # still experimental \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "from IPython.display import Image\n",
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "from tensorflow import keras\n",
    "\n",
    "# from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3b93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_select_547_train.csv\" , encoding = 'utf-8')\n",
    "X_te_new = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_select_547_test.csv\" , encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e2d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_train = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_num_features_train.csv\" , encoding = 'utf-8')\n",
    "num_features_test = pd.read_csv(os.path.abspath(\"../input\")+\"/choi_num_features_test.csv\" , encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2fb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv' , encoding = 'cp949').group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5e0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2af5ac5",
   "metadata": {},
   "source": [
    "# LGBM_BO Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce3b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM_BO Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba7ba26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, target, test_size=0.3, random_state = 0, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015ce5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "IDtest = num_features_train.custid.unique()\n",
    "\n",
    "pikle_data = (np.array(X_train), np.array(X_val), y_train, y_val, np.array(X_te_new), np.array(IDtest))\n",
    "\n",
    "with open('DNN_features.pkl', 'wb') as f:\n",
    "    pickle.dump(pikle_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd2c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c67a99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'n_estimators':(50, 500),\n",
    "    'learning_rate':(0.001, 0.1),\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_log_loss_eval(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":int(round(n_estimators)), \n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0),\n",
    "        'random_state':1000,\n",
    "        'n_jobs':-1\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict_proba(X_val)\n",
    "    LL = log_loss(y_val, valid_pred)\n",
    "    \n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261afa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... |  max_bin  | max_depth | min_ch... | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 1.606   \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 0.01239 \u001b[0m | \u001b[0m 475.6   \u001b[0m | \u001b[0m 11.86   \u001b[0m | \u001b[0m 175.8   \u001b[0m | \u001b[0m 11.4    \u001b[0m | \u001b[0m 68.32   \u001b[0m | \u001b[0m 39.89   \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 8.418   \u001b[0m | \u001b[0m 0.6035  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.25423\tvalid_1's multi_logloss: 1.47967\n",
      "[200]\ttraining's multi_logloss: 1.07755\tvalid_1's multi_logloss: 1.45989\n",
      "[300]\ttraining's multi_logloss: 0.956931\tvalid_1's multi_logloss: 1.456\n",
      "[400]\ttraining's multi_logloss: 0.868089\tvalid_1's multi_logloss: 1.45687\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 1.456   \u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 0.03982 \u001b[0m | \u001b[0m 99.31   \u001b[0m | \u001b[0m 13.95   \u001b[0m | \u001b[0m 23.22   \u001b[0m | \u001b[0m 44.38   \u001b[0m | \u001b[0m 478.7   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 20.78   \u001b[0m | \u001b[0m 0.2908  \u001b[0m | \u001b[0m 0.991   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.27896\tvalid_1's multi_logloss: 1.47438\n",
      "[200]\ttraining's multi_logloss: 1.22645\tvalid_1's multi_logloss: 1.46591\n",
      "[300]\ttraining's multi_logloss: 1.22326\tvalid_1's multi_logloss: 1.46558\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.07096 \u001b[0m | \u001b[0m 187.3   \u001b[0m | \u001b[0m 8.281   \u001b[0m | \u001b[0m 172.5   \u001b[0m | \u001b[0m 33.21   \u001b[0m | \u001b[0m 394.6   \u001b[0m | \u001b[0m 46.16   \u001b[0m | \u001b[0m 44.26   \u001b[0m | \u001b[0m 9.042   \u001b[0m | \u001b[0m 0.5052  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.24756\tvalid_1's multi_logloss: 1.48644\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.02522 \u001b[0m | \u001b[0m 75.32   \u001b[0m | \u001b[0m 13.58   \u001b[0m | \u001b[0m 85.66   \u001b[0m | \u001b[0m 44.27   \u001b[0m | \u001b[0m 131.5   \u001b[0m | \u001b[0m 41.3    \u001b[0m | \u001b[0m 0.917   \u001b[0m | \u001b[0m 6.915   \u001b[0m | \u001b[0m 0.7348  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.13596\tvalid_1's multi_logloss: 1.46212\n",
      "[200]\ttraining's multi_logloss: 1.06589\tvalid_1's multi_logloss: 1.45967\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 0.5641  \u001b[0m | \u001b[0m 0.08924 \u001b[0m | \u001b[0m 459.9   \u001b[0m | \u001b[0m 8.585   \u001b[0m | \u001b[0m 18.64   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 320.8   \u001b[0m | \u001b[0m 36.41   \u001b[0m | \u001b[0m 34.1    \u001b[0m | \u001b[0m 2.091   \u001b[0m | \u001b[0m 0.7598  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.5655  \u001b[0m | \u001b[0m 0.0899  \u001b[0m | \u001b[0m 385.8   \u001b[0m | \u001b[0m 12.48   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 13.98   \u001b[0m | \u001b[0m 53.89   \u001b[0m | \u001b[0m 58.9    \u001b[0m | \u001b[0m 3.343   \u001b[0m | \u001b[0m 4.566   \u001b[0m | \u001b[0m 0.8171  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.30851\tvalid_1's multi_logloss: 1.49332\n",
      "[200]\ttraining's multi_logloss: 1.14513\tvalid_1's multi_logloss: 1.46173\n",
      "[300]\ttraining's multi_logloss: 1.03296\tvalid_1's multi_logloss: 1.45381\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 1.452   \u001b[0m | \u001b[0m 0.5489  \u001b[0m | \u001b[0m 0.03395 \u001b[0m | \u001b[0m 64.96   \u001b[0m | \u001b[0m 13.84   \u001b[0m | \u001b[0m 65.5    \u001b[0m | \u001b[0m 37.87   \u001b[0m | \u001b[0m 355.0   \u001b[0m | \u001b[0m 48.02   \u001b[0m | \u001b[0m 21.2    \u001b[0m | \u001b[0m 9.522   \u001b[0m | \u001b[0m 0.599   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.03243\tvalid_1's multi_logloss: 1.46353\n",
      "[200]\ttraining's multi_logloss: 0.915378\tvalid_1's multi_logloss: 1.46444\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 0.6315  \u001b[0m | \u001b[0m 0.08962 \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 183.9   \u001b[0m | \u001b[0m 8.872   \u001b[0m | \u001b[0m 201.0   \u001b[0m | \u001b[0m 38.73   \u001b[0m | \u001b[0m 27.65   \u001b[0m | \u001b[0m 1.969   \u001b[0m | \u001b[0m 0.8596  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.594127\tvalid_1's multi_logloss: 1.46779\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.08917 \u001b[0m | \u001b[0m 241.4   \u001b[0m | \u001b[0m 9.347   \u001b[0m | \u001b[0m 170.4   \u001b[0m | \u001b[0m 22.65   \u001b[0m | \u001b[0m 359.8   \u001b[0m | \u001b[0m 58.81   \u001b[0m | \u001b[0m 1.244   \u001b[0m | \u001b[0m 9.426   \u001b[0m | \u001b[0m 0.8205  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 1.48    \u001b[0m | \u001b[0m 0.9497  \u001b[0m | \u001b[0m 0.05358 \u001b[0m | \u001b[0m 485.1   \u001b[0m | \u001b[0m 11.49   \u001b[0m | \u001b[0m 161.1   \u001b[0m | \u001b[0m 8.26    \u001b[0m | \u001b[0m 56.54   \u001b[0m | \u001b[0m 36.37   \u001b[0m | \u001b[0m 8.274   \u001b[0m | \u001b[0m 8.068   \u001b[0m | \u001b[0m 0.6856  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.60039\tvalid_1's multi_logloss: 1.64472\n",
      "[200]\ttraining's multi_logloss: 1.48919\tvalid_1's multi_logloss: 1.57\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 1.544   \u001b[0m | \u001b[0m 0.9753  \u001b[0m | \u001b[0m 0.007141\u001b[0m | \u001b[0m 150.5   \u001b[0m | \u001b[0m 10.85   \u001b[0m | \u001b[0m 126.7   \u001b[0m | \u001b[0m 29.2    \u001b[0m | \u001b[0m 265.4   \u001b[0m | \u001b[0m 27.8    \u001b[0m | \u001b[0m 38.66   \u001b[0m | \u001b[0m 5.93    \u001b[0m | \u001b[0m 0.6262  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.962405\tvalid_1's multi_logloss: 1.4688\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.8518  \u001b[0m | \u001b[0m 0.05792 \u001b[0m | \u001b[0m 97.41   \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 21.1    \u001b[0m | \u001b[0m 3.056   \u001b[0m | \u001b[0m 111.2   \u001b[0m | \u001b[0m 59.99   \u001b[0m | \u001b[0m 26.46   \u001b[0m | \u001b[0m 2.452   \u001b[0m | \u001b[0m 0.7119  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.42237\tvalid_1's multi_logloss: 1.53502\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 1.527   \u001b[0m | \u001b[0m 0.934   \u001b[0m | \u001b[0m 0.02159 \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 9.834   \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 9.714   \u001b[0m | \u001b[0m 109.6   \u001b[0m | \u001b[0m 49.51   \u001b[0m | \u001b[0m 44.53   \u001b[0m | \u001b[0m 6.01    \u001b[0m | \u001b[0m 0.7984  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.41324\tvalid_1's multi_logloss: 1.52043\n",
      "[200]\ttraining's multi_logloss: 1.31472\tvalid_1's multi_logloss: 1.48212\n",
      "[300]\ttraining's multi_logloss: 1.26545\tvalid_1's multi_logloss: 1.47045\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 0.02929 \u001b[0m | \u001b[0m 197.3   \u001b[0m | \u001b[0m 11.55   \u001b[0m | \u001b[0m 80.52   \u001b[0m | \u001b[0m 42.96   \u001b[0m | \u001b[0m 372.8   \u001b[0m | \u001b[0m 43.49   \u001b[0m | \u001b[0m 44.28   \u001b[0m | \u001b[0m 1.702   \u001b[0m | \u001b[0m 0.8876  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.76307\tvalid_1's multi_logloss: 1.77627\n",
      "[200]\ttraining's multi_logloss: 1.69782\tvalid_1's multi_logloss: 1.72325\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 1.695   \u001b[0m | \u001b[95m 0.7841  \u001b[0m | \u001b[95m 0.001698\u001b[0m | \u001b[95m 143.8   \u001b[0m | \u001b[95m 11.97   \u001b[0m | \u001b[95m 131.1   \u001b[0m | \u001b[95m 22.38   \u001b[0m | \u001b[95m 267.3   \u001b[0m | \u001b[95m 26.95   \u001b[0m | \u001b[95m 35.91   \u001b[0m | \u001b[95m 3.059   \u001b[0m | \u001b[95m 0.9364  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.47627\tvalid_1's multi_logloss: 1.57144\n",
      "[200]\ttraining's multi_logloss: 1.35048\tvalid_1's multi_logloss: 1.51089\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 1.493   \u001b[0m | \u001b[0m 0.6939  \u001b[0m | \u001b[0m 0.01438 \u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 9.234   \u001b[0m | \u001b[0m 130.8   \u001b[0m | \u001b[0m 16.24   \u001b[0m | \u001b[0m 267.0   \u001b[0m | \u001b[0m 33.2    \u001b[0m | \u001b[0m 37.03   \u001b[0m | \u001b[0m 6.381   \u001b[0m | \u001b[0m 0.8914  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.71726\tvalid_1's multi_logloss: 1.73809\n",
      "[200]\ttraining's multi_logloss: 1.63028\tvalid_1's multi_logloss: 1.66991\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 1.639   \u001b[0m | \u001b[0m 0.5857  \u001b[0m | \u001b[0m 0.003166\u001b[0m | \u001b[0m 156.3   \u001b[0m | \u001b[0m 12.96   \u001b[0m | \u001b[0m 132.2   \u001b[0m | \u001b[0m 27.25   \u001b[0m | \u001b[0m 263.8   \u001b[0m | \u001b[0m 33.68   \u001b[0m | \u001b[0m 40.42   \u001b[0m | \u001b[0m 4.588   \u001b[0m | \u001b[0m 0.6872  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.34138\tvalid_1's multi_logloss: 1.5003\n",
      "[200]\ttraining's multi_logloss: 1.21597\tvalid_1's multi_logloss: 1.46954\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.8053  \u001b[0m | \u001b[0m 0.03371 \u001b[0m | \u001b[0m 149.3   \u001b[0m | \u001b[0m 9.995   \u001b[0m | \u001b[0m 124.1   \u001b[0m | \u001b[0m 33.0    \u001b[0m | \u001b[0m 256.9   \u001b[0m | \u001b[0m 34.12   \u001b[0m | \u001b[0m 35.56   \u001b[0m | \u001b[0m 4.195   \u001b[0m | \u001b[0m 0.709   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.36551\tvalid_1's multi_logloss: 1.51514\n",
      "[200]\ttraining's multi_logloss: 1.23892\tvalid_1's multi_logloss: 1.47775\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 0.7364  \u001b[0m | \u001b[0m 0.02748 \u001b[0m | \u001b[0m 130.3   \u001b[0m | \u001b[0m 12.49   \u001b[0m | \u001b[0m 128.0   \u001b[0m | \u001b[0m 17.68   \u001b[0m | \u001b[0m 271.8   \u001b[0m | \u001b[0m 32.86   \u001b[0m | \u001b[0m 39.23   \u001b[0m | \u001b[0m 9.013   \u001b[0m | \u001b[0m 0.9734  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.11481\tvalid_1's multi_logloss: 1.4676\n",
      "[200]\ttraining's multi_logloss: 1.08461\tvalid_1's multi_logloss: 1.46639\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.09832 \u001b[0m | \u001b[0m 154.9   \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 127.2   \u001b[0m | \u001b[0m 17.46   \u001b[0m | \u001b[0m 273.1   \u001b[0m | \u001b[0m 48.4    \u001b[0m | \u001b[0m 37.14   \u001b[0m | \u001b[0m 7.111   \u001b[0m | \u001b[0m 0.7397  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.15719\tvalid_1's multi_logloss: 1.46933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's multi_logloss: 1.11805\tvalid_1's multi_logloss: 1.46686\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.6516  \u001b[0m | \u001b[0m 0.09152 \u001b[0m | \u001b[0m 158.6   \u001b[0m | \u001b[0m 11.56   \u001b[0m | \u001b[0m 124.0   \u001b[0m | \u001b[0m 15.84   \u001b[0m | \u001b[0m 258.0   \u001b[0m | \u001b[0m 37.98   \u001b[0m | \u001b[0m 39.34   \u001b[0m | \u001b[0m 8.326   \u001b[0m | \u001b[0m 0.9828  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.7061  \u001b[0m | \u001b[0m 0.08002 \u001b[0m | \u001b[0m 473.9   \u001b[0m | \u001b[0m 12.39   \u001b[0m | \u001b[0m 182.5   \u001b[0m | \u001b[0m 17.52   \u001b[0m | \u001b[0m 56.32   \u001b[0m | \u001b[0m 49.1    \u001b[0m | \u001b[0m 21.55   \u001b[0m | \u001b[0m 7.584   \u001b[0m | \u001b[0m 0.8887  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 1.543   \u001b[0m | \u001b[0m 0.5648  \u001b[0m | \u001b[0m 0.03875 \u001b[0m | \u001b[0m 65.62   \u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 88.48   \u001b[0m | \u001b[0m 1.118   \u001b[0m | \u001b[0m 51.35   \u001b[0m | \u001b[0m 35.48   \u001b[0m | \u001b[0m 38.55   \u001b[0m | \u001b[0m 8.34    \u001b[0m | \u001b[0m 0.9788  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 1.576   \u001b[0m | \u001b[0m 0.8235  \u001b[0m | \u001b[0m 0.01878 \u001b[0m | \u001b[0m 470.1   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 175.2   \u001b[0m | \u001b[0m 10.43   \u001b[0m | \u001b[0m 60.61   \u001b[0m | \u001b[0m 32.98   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 8.837   \u001b[0m | \u001b[0m 0.5008  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.992329\tvalid_1's multi_logloss: 1.45477\n",
      "[200]\ttraining's multi_logloss: 0.69464\tvalid_1's multi_logloss: 1.45644\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 0.05377 \u001b[0m | \u001b[0m 84.75   \u001b[0m | \u001b[0m 10.7    \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 45.29   \u001b[0m | \u001b[0m 250.6   \u001b[0m | \u001b[0m 50.68   \u001b[0m | \u001b[0m 0.3493  \u001b[0m | \u001b[0m 9.987   \u001b[0m | \u001b[0m 0.5655  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.32633\tvalid_1's multi_logloss: 1.49272\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 1.478   \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 0.04093 \u001b[0m | \u001b[0m 142.4   \u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 39.88   \u001b[0m | \u001b[0m 35.72   \u001b[0m | \u001b[0m 143.9   \u001b[0m | \u001b[0m 44.61   \u001b[0m | \u001b[0m 39.49   \u001b[0m | \u001b[0m 3.706   \u001b[0m | \u001b[0m 0.9244  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.57039\tvalid_1's multi_logloss: 1.65153\n",
      "[200]\ttraining's multi_logloss: 1.41983\tvalid_1's multi_logloss: 1.56656\n",
      "[300]\ttraining's multi_logloss: 1.31673\tvalid_1's multi_logloss: 1.5237\n",
      "[400]\ttraining's multi_logloss: 1.23549\tvalid_1's multi_logloss: 1.4988\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 1.485   \u001b[0m | \u001b[0m 0.6451  \u001b[0m | \u001b[0m 0.005897\u001b[0m | \u001b[0m 171.4   \u001b[0m | \u001b[0m 9.761   \u001b[0m | \u001b[0m 45.17   \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 478.6   \u001b[0m | \u001b[0m 44.85   \u001b[0m | \u001b[0m 14.2    \u001b[0m | \u001b[0m 2.572   \u001b[0m | \u001b[0m 0.6846  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 0.6697  \u001b[0m | \u001b[0m 0.08727 \u001b[0m | \u001b[0m 479.9   \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 183.1   \u001b[0m | \u001b[0m 10.77   \u001b[0m | \u001b[0m 62.94   \u001b[0m | \u001b[0m 25.28   \u001b[0m | \u001b[0m 8.324   \u001b[0m | \u001b[0m 3.289   \u001b[0m | \u001b[0m 0.5943  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.13522\tvalid_1's multi_logloss: 1.47015\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 0.9271  \u001b[0m | \u001b[0m 0.05662 \u001b[0m | \u001b[0m 44.3    \u001b[0m | \u001b[0m 11.51   \u001b[0m | \u001b[0m 195.1   \u001b[0m | \u001b[0m 8.755   \u001b[0m | \u001b[0m 197.2   \u001b[0m | \u001b[0m 62.77   \u001b[0m | \u001b[0m 26.33   \u001b[0m | \u001b[0m 7.901   \u001b[0m | \u001b[0m 0.5467  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.3174\tvalid_1's multi_logloss: 1.49561\n",
      "[200]\ttraining's multi_logloss: 1.21647\tvalid_1's multi_logloss: 1.47347\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 1.471   \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.04156 \u001b[0m | \u001b[0m 166.0   \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 127.6   \u001b[0m | \u001b[0m 23.28   \u001b[0m | \u001b[0m 263.5   \u001b[0m | \u001b[0m 28.08   \u001b[0m | \u001b[0m 44.31   \u001b[0m | \u001b[0m 7.457   \u001b[0m | \u001b[0m 0.8313  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.08752 \u001b[0m | \u001b[0m 473.3   \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 176.1   \u001b[0m | \u001b[0m 1.579   \u001b[0m | \u001b[0m 59.59   \u001b[0m | \u001b[0m 29.46   \u001b[0m | \u001b[0m 18.15   \u001b[0m | \u001b[0m 8.241   \u001b[0m | \u001b[0m 0.8668  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.2423\tvalid_1's multi_logloss: 1.47561\n",
      "[200]\ttraining's multi_logloss: 1.15577\tvalid_1's multi_logloss: 1.46477\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 1.464   \u001b[0m | \u001b[0m 0.7824  \u001b[0m | \u001b[0m 0.06605 \u001b[0m | \u001b[0m 142.6   \u001b[0m | \u001b[0m 9.141   \u001b[0m | \u001b[0m 128.2   \u001b[0m | \u001b[0m 31.83   \u001b[0m | \u001b[0m 272.7   \u001b[0m | \u001b[0m 29.15   \u001b[0m | \u001b[0m 38.07   \u001b[0m | \u001b[0m 9.819   \u001b[0m | \u001b[0m 0.9451  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.47905\tvalid_1's multi_logloss: 1.56371\n",
      "[200]\ttraining's multi_logloss: 1.36323\tvalid_1's multi_logloss: 1.5076\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 1.489   \u001b[0m | \u001b[0m 0.7853  \u001b[0m | \u001b[0m 0.0161  \u001b[0m | \u001b[0m 156.8   \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 143.6   \u001b[0m | \u001b[0m 30.42   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 34.73   \u001b[0m | \u001b[0m 39.53   \u001b[0m | \u001b[0m 9.989   \u001b[0m | \u001b[0m 0.8632  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 0.8345  \u001b[0m | \u001b[0m 0.03011 \u001b[0m | \u001b[0m 471.0   \u001b[0m | \u001b[0m 13.85   \u001b[0m | \u001b[0m 182.1   \u001b[0m | \u001b[0m 11.9    \u001b[0m | \u001b[0m 75.17   \u001b[0m | \u001b[0m 48.4    \u001b[0m | \u001b[0m 11.49   \u001b[0m | \u001b[0m 1.695   \u001b[0m | \u001b[0m 0.7594  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.01386\tvalid_1's multi_logloss: 1.46288\n",
      "[200]\ttraining's multi_logloss: 0.867613\tvalid_1's multi_logloss: 1.46438\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.8572  \u001b[0m | \u001b[0m 0.09739 \u001b[0m | \u001b[0m 248.8   \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 30.63   \u001b[0m | \u001b[0m 410.8   \u001b[0m | \u001b[0m 54.97   \u001b[0m | \u001b[0m 24.66   \u001b[0m | \u001b[0m 2.474   \u001b[0m | \u001b[0m 0.8755  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.983012\tvalid_1's multi_logloss: 1.45959\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.9843  \u001b[0m | \u001b[0m 0.05701 \u001b[0m | \u001b[0m 109.6   \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 196.3   \u001b[0m | \u001b[0m 39.79   \u001b[0m | \u001b[0m 192.8   \u001b[0m | \u001b[0m 56.91   \u001b[0m | \u001b[0m 4.085   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 0.9406  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.19057\tvalid_1's multi_logloss: 1.46599\n",
      "[200]\ttraining's multi_logloss: 1.12011\tvalid_1's multi_logloss: 1.46192\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.7072  \u001b[0m | \u001b[0m 0.0825  \u001b[0m | \u001b[0m 157.7   \u001b[0m | \u001b[0m 11.79   \u001b[0m | \u001b[0m 119.5   \u001b[0m | \u001b[0m 29.45   \u001b[0m | \u001b[0m 263.7   \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 36.46   \u001b[0m | \u001b[0m 5.519   \u001b[0m | \u001b[0m 0.7987  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.32194\tvalid_1's multi_logloss: 1.49019\n",
      "[200]\ttraining's multi_logloss: 1.23966\tvalid_1's multi_logloss: 1.47124\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.04748 \u001b[0m | \u001b[0m 154.5   \u001b[0m | \u001b[0m 11.7    \u001b[0m | \u001b[0m 125.9   \u001b[0m | \u001b[0m 31.37   \u001b[0m | \u001b[0m 269.0   \u001b[0m | \u001b[0m 27.75   \u001b[0m | \u001b[0m 46.0    \u001b[0m | \u001b[0m 3.26    \u001b[0m | \u001b[0m 0.5198  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.29644\tvalid_1's multi_logloss: 1.49301\n",
      "[200]\ttraining's multi_logloss: 1.18877\tvalid_1's multi_logloss: 1.4692\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 0.692   \u001b[0m | \u001b[0m 0.03881 \u001b[0m | \u001b[0m 447.6   \u001b[0m | \u001b[0m 12.21   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 4.126   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 45.34   \u001b[0m | \u001b[0m 42.45   \u001b[0m | \u001b[0m 5.131   \u001b[0m | \u001b[0m 0.8917  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.14212\tvalid_1's multi_logloss: 1.46397\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.6007  \u001b[0m | \u001b[0m 0.08275 \u001b[0m | \u001b[0m 286.0   \u001b[0m | \u001b[0m 13.52   \u001b[0m | \u001b[0m 191.0   \u001b[0m | \u001b[0m 10.98   \u001b[0m | \u001b[0m 103.4   \u001b[0m | \u001b[0m 49.5    \u001b[0m | \u001b[0m 33.48   \u001b[0m | \u001b[0m 9.573   \u001b[0m | \u001b[0m 0.5761  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.23824\tvalid_1's multi_logloss: 1.47444\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.07193 \u001b[0m | \u001b[0m 281.8   \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 189.4   \u001b[0m | \u001b[0m 3.006   \u001b[0m | \u001b[0m 109.0   \u001b[0m | \u001b[0m 39.97   \u001b[0m | \u001b[0m 44.8    \u001b[0m | \u001b[0m 9.434   \u001b[0m | \u001b[0m 0.9095  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.41505\tvalid_1's multi_logloss: 1.53894\n",
      "[200]\ttraining's multi_logloss: 1.27432\tvalid_1's multi_logloss: 1.49023\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.01858 \u001b[0m | \u001b[0m 149.4   \u001b[0m | \u001b[0m 15.59   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 24.37   \u001b[0m | \u001b[0m 266.3   \u001b[0m | \u001b[0m 43.42   \u001b[0m | \u001b[0m 29.64   \u001b[0m | \u001b[0m 8.166   \u001b[0m | \u001b[0m 0.5638  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 0.635   \u001b[0m | \u001b[0m 0.0422  \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 9.306   \u001b[0m | \u001b[0m 176.6   \u001b[0m | \u001b[0m 20.29   \u001b[0m | \u001b[0m 72.42   \u001b[0m | \u001b[0m 34.85   \u001b[0m | \u001b[0m 13.39   \u001b[0m | \u001b[0m 6.557   \u001b[0m | \u001b[0m 0.8249  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.53231\tvalid_1's multi_logloss: 1.60095\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 1.591   \u001b[0m | \u001b[0m 0.7846  \u001b[0m | \u001b[0m 0.011   \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 191.9   \u001b[0m | \u001b[0m 17.14   \u001b[0m | \u001b[0m 108.9   \u001b[0m | \u001b[0m 54.02   \u001b[0m | \u001b[0m 39.89   \u001b[0m | \u001b[0m 4.221   \u001b[0m | \u001b[0m 0.6714  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.40958\tvalid_1's multi_logloss: 1.56489\n",
      "[200]\ttraining's multi_logloss: 1.222\tvalid_1's multi_logloss: 1.49696\n",
      "[300]\ttraining's multi_logloss: 1.08903\tvalid_1's multi_logloss: 1.47076\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.5358  \u001b[0m | \u001b[0m 0.0126  \u001b[0m | \u001b[0m 246.8   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 117.5   \u001b[0m | \u001b[0m 5.412   \u001b[0m | \u001b[0m 383.1   \u001b[0m | \u001b[0m 41.53   \u001b[0m | \u001b[0m 13.23   \u001b[0m | \u001b[0m 6.24    \u001b[0m | \u001b[0m 0.5461  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.601097\tvalid_1's multi_logloss: 1.46548\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.06378 \u001b[0m | \u001b[0m 352.4   \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 139.0   \u001b[0m | \u001b[0m 6.911   \u001b[0m | \u001b[0m 262.4   \u001b[0m | \u001b[0m 45.78   \u001b[0m | \u001b[0m 1.28    \u001b[0m | \u001b[0m 8.062   \u001b[0m | \u001b[0m 0.5683  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.20798\tvalid_1's multi_logloss: 1.47065\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 1.47    \u001b[0m | \u001b[0m 0.7734  \u001b[0m | \u001b[0m 0.08886 \u001b[0m | \u001b[0m 293.6   \u001b[0m | \u001b[0m 10.28   \u001b[0m | \u001b[0m 184.6   \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 110.8   \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 41.28   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.7115  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.2732\tvalid_1's multi_logloss: 1.47503\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 1.471   \u001b[0m | \u001b[0m 0.519   \u001b[0m | \u001b[0m 0.06869 \u001b[0m | \u001b[0m 276.8   \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 191.8   \u001b[0m | \u001b[0m 25.38   \u001b[0m | \u001b[0m 116.6   \u001b[0m | \u001b[0m 56.6    \u001b[0m | \u001b[0m 43.98   \u001b[0m | \u001b[0m 4.888   \u001b[0m | \u001b[0m 0.7652  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.22252\tvalid_1's multi_logloss: 1.47767\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 1.475   \u001b[0m | \u001b[0m 0.9469  \u001b[0m | \u001b[0m 0.08172 \u001b[0m | \u001b[0m 467.8   \u001b[0m | \u001b[0m 13.47   \u001b[0m | \u001b[0m 122.7   \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 177.0   \u001b[0m | \u001b[0m 53.74   \u001b[0m | \u001b[0m 48.6    \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 0.925   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.37092\tvalid_1's multi_logloss: 1.52456\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 1.492   \u001b[0m | \u001b[0m 0.9972  \u001b[0m | \u001b[0m 0.01748 \u001b[0m | \u001b[0m 120.4   \u001b[0m | \u001b[0m 11.72   \u001b[0m | \u001b[0m 172.2   \u001b[0m | \u001b[0m 33.55   \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 47.13   \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 1.432   \u001b[0m | \u001b[0m 0.8877  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.20813\tvalid_1's multi_logloss: 1.46969\n",
      "[200]\ttraining's multi_logloss: 1.18543\tvalid_1's multi_logloss: 1.46719\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.09359 \u001b[0m | \u001b[0m 131.6   \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 132.1   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 260.5   \u001b[0m | \u001b[0m 24.46   \u001b[0m | \u001b[0m 43.12   \u001b[0m | \u001b[0m 1.287   \u001b[0m | \u001b[0m 0.9477  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.49718\tvalid_1's multi_logloss: 1.5741\n",
      "[200]\ttraining's multi_logloss: 1.38848\tvalid_1's multi_logloss: 1.51591\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 1.498   \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.01438 \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 8.545   \u001b[0m | \u001b[0m 130.5   \u001b[0m | \u001b[0m 24.58   \u001b[0m | \u001b[0m 268.6   \u001b[0m | \u001b[0m 30.35   \u001b[0m | \u001b[0m 46.73   \u001b[0m | \u001b[0m 2.793   \u001b[0m | \u001b[0m 0.7915  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.8563  \u001b[0m | \u001b[0m 0.09341 \u001b[0m | \u001b[0m 480.0   \u001b[0m | \u001b[0m 8.833   \u001b[0m | \u001b[0m 181.1   \u001b[0m | \u001b[0m 8.537   \u001b[0m | \u001b[0m 69.96   \u001b[0m | \u001b[0m 53.74   \u001b[0m | \u001b[0m 11.21   \u001b[0m | \u001b[0m 6.605   \u001b[0m | \u001b[0m 0.944   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 1.492   \u001b[0m | \u001b[0m 0.7254  \u001b[0m | \u001b[0m 0.04755 \u001b[0m | \u001b[0m 285.4   \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 6.181   \u001b[0m | \u001b[0m 98.45   \u001b[0m | \u001b[0m 52.82   \u001b[0m | \u001b[0m 48.93   \u001b[0m | \u001b[0m 7.855   \u001b[0m | \u001b[0m 0.6888  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.68324\tvalid_1's multi_logloss: 1.71017\n",
      "[200]\ttraining's multi_logloss: 1.58532\tvalid_1's multi_logloss: 1.63569\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 1.606   \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 0.004398\u001b[0m | \u001b[0m 151.4   \u001b[0m | \u001b[0m 11.67   \u001b[0m | \u001b[0m 145.9   \u001b[0m | \u001b[0m 27.17   \u001b[0m | \u001b[0m 260.4   \u001b[0m | \u001b[0m 37.68   \u001b[0m | \u001b[0m 41.24   \u001b[0m | \u001b[0m 9.415   \u001b[0m | \u001b[0m 0.802   \u001b[0m |\n",
      "=============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f = lgb_log_loss_eval, pbounds=bayesian_params, random_state=1000)\n",
    "lgbBO.maximize(init_points=5, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426bc1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6060982858125845, 1.4556068675499798, 1.4655825658321555, 1.4688808847928827, 1.4591822611433771, 1.4669657412254045, 1.452348853289662, 1.4645161000335565, 1.4626696571767683, 1.4799900664906072, 1.5443871109560476, 1.4671639551435856, 1.5274123757440137, 1.4675921068085074, 1.6950039702477975, 1.4933062656887393, 1.638815821205718, 1.4627763950780488, 1.4680463155627095, 1.4662920486477267, 1.4668566526359093, 1.4767312387673706, 1.5428294883105653, 1.5758729620943188, 1.4624938648355332, 1.4781610996959282, 1.4854362789477158, 1.468151754343313, 1.459436314821971, 1.4713478269480162, 1.4730684078905438, 1.4642859113913247, 1.4891334602953101, 1.4998583551808504, 1.461139181123826, 1.4627578493200197, 1.4619787961882376, 1.4690911586541557, 1.467681102742748, 1.4632863093789008, 1.4727158703805407, 1.4774825834921883, 1.4877343294300907, 1.5913676784636825, 1.4607328430612407, 1.4634965955517054, 1.4699443732746134, 1.470698345132294, 1.4753763253485417, 1.4921084861715843, 1.467185929474085, 1.4983291178144256, 1.4665543741677465, 1.4916799327114199, 1.6059683411587007]\n",
      "maximum target index: 6\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159c1eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 1.452348853289662, 'params': {'colsample_bytree': 0.5489297647691318, 'learning_rate': 0.033947270113616715, 'max_bin': 64.96058512468377, 'max_depth': 13.838623612170684, 'min_child_samples': 65.50145788216062, 'min_child_weight': 37.87286066499082, 'n_estimators': 355.00257308928775, 'num_leaves': 48.02022146460943, 'reg_alpha': 21.197890290451262, 'reg_lambda': 9.521528307448555, 'subsample': 0.5990212685265623}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc8505",
   "metadata": {},
   "source": [
    "# *OOF 스태킹*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04f04938",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv' , encoding = 'cp949').group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df2c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939f18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b59fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d2a0b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 547), (14380, 547))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape, X_te_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df4e08b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof_ver2 = np.zeros((X_new.shape[0], 19))\n",
    "lgb_oof_ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236f8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# FE\n",
    "from scipy.signal import find_peaks, peak_widths, peak_prominences\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ensemble\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0593f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de4730",
   "metadata": {},
   "source": [
    "{'target': 1.452348853289662, 'params': {'colsample_bytree': 0.5489297647691318, 'learning_rate': 0.033947270113616715, 'max_bin': 64.96058512468377, 'max_depth': 13.838623612170684, 'min_child_samples': 65.50145788216062, 'min_child_weight': 37.87286066499082, 'n_estimators': 355.00257308928775, 'num_leaves': 48.02022146460943, 'reg_alpha': 21.197890290451262, 'reg_lambda': 9.521528307448555, 'subsample': 0.5990212685265623}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17d36f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad346084",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(\n",
    "                objective='multiclass',\n",
    "                metric='multi_logloss',\n",
    "                nthread=4,\n",
    "                n_estimators=355,\n",
    "                learning_rate=0.033947270113616715,\n",
    "                max_bin=65,\n",
    "                max_depth=14,\n",
    "                num_leaves=48,\n",
    "                colsample_bytree=0.5489297647691318,\n",
    "                subsample=0.5990212685265623,\n",
    "                reg_alpha=21.197890290451262,\n",
    "                reg_lambda=9.521528307448555,\n",
    "                min_child_samples=66,\n",
    "                min_child_weight=37.87286066499082,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                random_state=1000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9546172b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15848\tvalid_1's multi_logloss: 1.44976\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15476\tvalid_1's multi_logloss: 1.46388\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15675\tvalid_1's multi_logloss: 1.46218\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15422\tvalid_1's multi_logloss: 1.47452\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15665\tvalid_1's multi_logloss: 1.44548\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15857\tvalid_1's multi_logloss: 1.43763\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15478\tvalid_1's multi_logloss: 1.4536\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15647\tvalid_1's multi_logloss: 1.44648\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15853\tvalid_1's multi_logloss: 1.43561\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15536\tvalid_1's multi_logloss: 1.45459\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "lgb ver2 logloss=  1.4423044571782404\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15762\tvalid_1's multi_logloss: 1.44103\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15617\tvalid_1's multi_logloss: 1.4579\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15585\tvalid_1's multi_logloss: 1.47104\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.1586\tvalid_1's multi_logloss: 1.44205\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15343\tvalid_1's multi_logloss: 1.47107\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15607\tvalid_1's multi_logloss: 1.45476\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15712\tvalid_1's multi_logloss: 1.43099\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15662\tvalid_1's multi_logloss: 1.44208\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15713\tvalid_1's multi_logloss: 1.4475\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.15449\tvalid_1's multi_logloss: 1.46998\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "lgb ver2 logloss=  1.4388279611585069\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "mlogloss = []\n",
    "lgb_oof_ver2 = np.zeros((X_new.shape[0], 8))\n",
    "lgb_pred_ver2 = np.zeros((X_te_new.shape[0], 8))\n",
    "\n",
    "for X, X_test in [(X_new,X_te_new)]:\n",
    "    X= X.reset_index(drop=True)\n",
    "    for seed in [0,1000]:\n",
    "        kfold = StratifiedKFold(n_splits=n_splits, random_state= seed, shuffle=True)\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "            X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "            y_train, y_valid = y[trn_idx], y[val_idx]\n",
    "\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "            # Predict\n",
    "            lgb_pred_ver2 += clf.predict_proba(X_test) / (n_splits * 4)\n",
    "            lgb_oof_ver2[val_idx] += clf.predict_proba(X_valid) / 4\n",
    "            print('*'* 85)\n",
    "            print('Training has finished.')\n",
    "        print('lgb ver2 logloss= ', log_loss(y, lgb_oof_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04ef66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oof = np.column_stack([lgb_oof_ver2])\n",
    "all_test = np.column_stack([lgb_pred_ver2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03d35f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043863</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.076121</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.174054</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>0.070654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.079079</td>\n",
       "      <td>0.157967</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.196939</td>\n",
       "      <td>0.023625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382456</td>\n",
       "      <td>0.089427</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296074</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.071908</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>0.012151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.436762</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.002585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.214441</td>\n",
       "      <td>0.040246</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.047645</td>\n",
       "      <td>0.009925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.173447</td>\n",
       "      <td>0.130976</td>\n",
       "      <td>0.048655</td>\n",
       "      <td>0.028464</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.021308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0.177087</td>\n",
       "      <td>0.081713</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.045639</td>\n",
       "      <td>0.032437</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.038649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.069617</td>\n",
       "      <td>0.199166</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>0.115048</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.360932</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.006025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.043863  0.056851  0.018624  0.076121  0.043695  0.174054  0.016139   \n",
       "1      0.014689  0.079079  0.157967  0.008213  0.002926  0.016560  0.196939   \n",
       "2      0.382456  0.089427  0.007827  0.004077  0.005917  0.004133  0.001771   \n",
       "3      0.296074  0.051171  0.022629  0.019292  0.015418  0.071908  0.011358   \n",
       "4      0.436762  0.026952  0.006998  0.003268  0.014175  0.005745  0.003516   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  0.034244  0.214441  0.040246  0.012426  0.012738  0.128336  0.047645   \n",
       "14376  0.173447  0.130976  0.048655  0.028464  0.020169  0.048308  0.028673   \n",
       "14377  0.177087  0.081713  0.051533  0.045639  0.032437  0.052109  0.020833   \n",
       "14378  0.069617  0.199166  0.047143  0.010714  0.015145  0.115048  0.035688   \n",
       "14379  0.360932  0.042910  0.022676  0.007212  0.022162  0.027206  0.010878   \n",
       "\n",
       "              7  \n",
       "0      0.070654  \n",
       "1      0.023625  \n",
       "2      0.004393  \n",
       "3      0.012151  \n",
       "4      0.002585  \n",
       "...         ...  \n",
       "14375  0.009925  \n",
       "14376  0.021308  \n",
       "14377  0.038649  \n",
       "14378  0.007477  \n",
       "14379  0.006025  \n",
       "\n",
       "[14380 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35145ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19429, 547)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d582ccb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14380, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26e7a81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41369\tvalid_1's multi_logloss: 1.43158\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41256\tvalid_1's multi_logloss: 1.44315\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.40926\tvalid_1's multi_logloss: 1.46161\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.4128\tvalid_1's multi_logloss: 1.43378\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.40961\tvalid_1's multi_logloss: 1.47002\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41109\tvalid_1's multi_logloss: 1.45214\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41402\tvalid_1's multi_logloss: 1.42645\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41238\tvalid_1's multi_logloss: 1.43991\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.41158\tvalid_1's multi_logloss: 1.44692\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.40957\tvalid_1's multi_logloss: 1.46346\n",
      "mean logloss=  nan\n"
     ]
    }
   ],
   "source": [
    "mlogloss = []\n",
    "n_splits = 10\n",
    "\n",
    "stk_oof_pred = np.zeros((all_oof.shape[0], 8))\n",
    "stk_test_pred = np.zeros((all_test.shape[0], 8))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits, random_state=1000, shuffle=True)\n",
    "for fold, (trn_idx, val_idx) in enumerate(kfold.split(all_oof, y)):\n",
    "    X_train, X_valid = all_oof[trn_idx], all_oof[val_idx]\n",
    "    y_train, y_valid = y[trn_idx], y[val_idx]\n",
    "            \n",
    "    clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "\n",
    "\n",
    "    stk_test_pred += clf.predict_proba(all_test) / n_splits\n",
    "    stk_oof_pred[val_idx] = clf.predict_proba(X_valid)\n",
    "    \n",
    "print('mean logloss= ',np.mean(mlogloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb104e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_test_pred = pd.DataFrame(stk_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "399a3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_test_pred = stk_test_pred.rename(columns = {0:'F20',1:'F30',2:'F40',3:'F50',4:'M20',5:'M30',6:'M40',7:'M50'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f597749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>F50</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "      <th>M50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091214</td>\n",
       "      <td>0.107264</td>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.157093</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.320539</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>0.172909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.145901</td>\n",
       "      <td>0.428837</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.316705</td>\n",
       "      <td>0.034115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765611</td>\n",
       "      <td>0.160336</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.008716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545416</td>\n",
       "      <td>0.147426</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>0.023451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858288</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.011706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.073224</td>\n",
       "      <td>0.401464</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>0.013627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.381390</td>\n",
       "      <td>0.268226</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>0.086820</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>0.034823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0.345633</td>\n",
       "      <td>0.174871</td>\n",
       "      <td>0.103964</td>\n",
       "      <td>0.099055</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.113580</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.127541</td>\n",
       "      <td>0.428154</td>\n",
       "      <td>0.077704</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.224028</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>0.014249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.725386</td>\n",
       "      <td>0.099423</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.045780</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.013302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F20       F30       F40       F50       M20       M30       M40  \\\n",
       "0      0.091214  0.107264  0.036091  0.157093  0.085900  0.320539  0.028990   \n",
       "1      0.014220  0.145901  0.428837  0.022665  0.007769  0.029788  0.316705   \n",
       "2      0.765611  0.160336  0.013934  0.011439  0.012696  0.020701  0.006567   \n",
       "3      0.545416  0.147426  0.047545  0.041071  0.074535  0.096943  0.023613   \n",
       "4      0.858288  0.055778  0.014141  0.011092  0.026631  0.016289  0.006075   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  0.073224  0.401464  0.083367  0.019107  0.015923  0.283476  0.109812   \n",
       "14376  0.381390  0.268226  0.100962  0.046113  0.035342  0.086820  0.046323   \n",
       "14377  0.345633  0.174871  0.103964  0.099055  0.061212  0.113580  0.035984   \n",
       "14378  0.127541  0.428154  0.077704  0.016760  0.022703  0.224028  0.088861   \n",
       "14379  0.725386  0.099423  0.028504  0.013718  0.059727  0.045780  0.014160   \n",
       "\n",
       "            M50  \n",
       "0      0.172909  \n",
       "1      0.034115  \n",
       "2      0.008716  \n",
       "3      0.023451  \n",
       "4      0.011706  \n",
       "...         ...  \n",
       "14375  0.013627  \n",
       "14376  0.034823  \n",
       "14377  0.065700  \n",
       "14378  0.014249  \n",
       "14379  0.013302  \n",
       "\n",
       "[14380 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d9410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_id = num_features_test['custid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73df6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.DataFrame({'ID':tst_id}),stk_test_pred],axis = 1)\n",
    "submission.to_csv('choi_lgbm_stk_oof_10.csv',index = False,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45cf7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>F50</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "      <th>M50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.091214</td>\n",
       "      <td>0.107264</td>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.157093</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.320539</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>0.172909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>0.145901</td>\n",
       "      <td>0.428837</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.316705</td>\n",
       "      <td>0.034115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.765611</td>\n",
       "      <td>0.160336</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.008716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>0.545416</td>\n",
       "      <td>0.147426</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.074535</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>0.023451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>0.858288</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.011706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>0.073224</td>\n",
       "      <td>0.401464</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.283476</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>0.013627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>0.381390</td>\n",
       "      <td>0.268226</td>\n",
       "      <td>0.100962</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>0.086820</td>\n",
       "      <td>0.046323</td>\n",
       "      <td>0.034823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>0.345633</td>\n",
       "      <td>0.174871</td>\n",
       "      <td>0.103964</td>\n",
       "      <td>0.099055</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.113580</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>0.428154</td>\n",
       "      <td>0.077704</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.224028</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>0.014249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>0.725386</td>\n",
       "      <td>0.099423</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.045780</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.013302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID       F20       F30       F40       F50       M20       M30  \\\n",
       "0      30001  0.091214  0.107264  0.036091  0.157093  0.085900  0.320539   \n",
       "1      30002  0.014220  0.145901  0.428837  0.022665  0.007769  0.029788   \n",
       "2      30003  0.765611  0.160336  0.013934  0.011439  0.012696  0.020701   \n",
       "3      30005  0.545416  0.147426  0.047545  0.041071  0.074535  0.096943   \n",
       "4      30007  0.858288  0.055778  0.014141  0.011092  0.026631  0.016289   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  49988  0.073224  0.401464  0.083367  0.019107  0.015923  0.283476   \n",
       "14376  49990  0.381390  0.268226  0.100962  0.046113  0.035342  0.086820   \n",
       "14377  49992  0.345633  0.174871  0.103964  0.099055  0.061212  0.113580   \n",
       "14378  49993  0.127541  0.428154  0.077704  0.016760  0.022703  0.224028   \n",
       "14379  49994  0.725386  0.099423  0.028504  0.013718  0.059727  0.045780   \n",
       "\n",
       "            M40       M50  \n",
       "0      0.028990  0.172909  \n",
       "1      0.316705  0.034115  \n",
       "2      0.006567  0.008716  \n",
       "3      0.023613  0.023451  \n",
       "4      0.006075  0.011706  \n",
       "...         ...       ...  \n",
       "14375  0.109812  0.013627  \n",
       "14376  0.046323  0.034823  \n",
       "14377  0.035984  0.065700  \n",
       "14378  0.088861  0.014249  \n",
       "14379  0.014160  0.013302  \n",
       "\n",
       "[14380 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cdbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a03309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd78bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12018cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
