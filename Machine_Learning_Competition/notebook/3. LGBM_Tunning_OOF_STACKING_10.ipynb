{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08505bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Users\\choij\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "# import klib\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer  # still experimental \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "from IPython.display import Image\n",
    "# import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "from tensorflow import keras\n",
    "\n",
    "# from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3b93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.read_csv(os.path.abspath(\"../input\")+\"/1round_third_select_499_train.csv\" , encoding = 'utf-8')\n",
    "X_te_new = pd.read_csv(os.path.abspath(\"../input\")+\"/1round_third_select_499_test.csv\" , encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e2d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_train = pd.read_csv(os.path.abspath(\"../input\")+\"/X_train.csv\" , encoding ='cp949')\n",
    "num_features_test = pd.read_csv(os.path.abspath(\"../input\")+\"/X_test.csv\" , encoding ='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2fb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv' , encoding = 'cp949').group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5e0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2af5ac5",
   "metadata": {},
   "source": [
    "# LGBM_BO Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce3b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM_BO Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba7ba26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, target, test_size=0.3, random_state = 0, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015ce5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "IDtest = num_features_train.custid.unique()\n",
    "\n",
    "pikle_data = (np.array(X_train), np.array(X_val), y_train, y_val, np.array(X_te_new), np.array(IDtest))\n",
    "\n",
    "with open('DNN_features.pkl', 'wb') as f:\n",
    "    pickle.dump(pikle_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd2c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67a99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'n_estimators':(50, 500),\n",
    "    'learning_rate':(0.001, 0.1),\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_log_loss_eval(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":int(round(n_estimators)), \n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0),\n",
    "        'random_state':1000,\n",
    "        'n_jobs':-1\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric= 'logloss', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict_proba(X_val)\n",
    "    LL = log_loss(y_val, valid_pred)\n",
    "    \n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261afa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... |  max_bin  | max_depth | min_ch... | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 1.618   \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 0.01239 \u001b[0m | \u001b[0m 475.6   \u001b[0m | \u001b[0m 11.86   \u001b[0m | \u001b[0m 175.8   \u001b[0m | \u001b[0m 11.4    \u001b[0m | \u001b[0m 68.32   \u001b[0m | \u001b[0m 39.89   \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 8.418   \u001b[0m | \u001b[0m 0.6035  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.36263\tvalid_1's multi_logloss: 1.50144\n",
      "[200]\ttraining's multi_logloss: 1.24786\tvalid_1's multi_logloss: 1.48094\n",
      "[300]\ttraining's multi_logloss: 1.17572\tvalid_1's multi_logloss: 1.47725\n",
      "[400]\ttraining's multi_logloss: 1.13489\tvalid_1's multi_logloss: 1.478\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.8712  \u001b[0m | \u001b[0m 0.03982 \u001b[0m | \u001b[0m 99.31   \u001b[0m | \u001b[0m 13.95   \u001b[0m | \u001b[0m 23.22   \u001b[0m | \u001b[0m 44.38   \u001b[0m | \u001b[0m 478.7   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 20.78   \u001b[0m | \u001b[0m 0.2908  \u001b[0m | \u001b[0m 0.991   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.39872\tvalid_1's multi_logloss: 1.50492\n",
      "[200]\ttraining's multi_logloss: 1.37685\tvalid_1's multi_logloss: 1.49863\n",
      "[300]\ttraining's multi_logloss: 1.37684\tvalid_1's multi_logloss: 1.49862\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 1.499   \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.07096 \u001b[0m | \u001b[0m 187.3   \u001b[0m | \u001b[0m 8.281   \u001b[0m | \u001b[0m 172.5   \u001b[0m | \u001b[0m 33.21   \u001b[0m | \u001b[0m 394.6   \u001b[0m | \u001b[0m 46.16   \u001b[0m | \u001b[0m 44.26   \u001b[0m | \u001b[0m 9.042   \u001b[0m | \u001b[0m 0.5052  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.33037\tvalid_1's multi_logloss: 1.50249\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 1.487   \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.02522 \u001b[0m | \u001b[0m 75.32   \u001b[0m | \u001b[0m 13.58   \u001b[0m | \u001b[0m 85.66   \u001b[0m | \u001b[0m 44.27   \u001b[0m | \u001b[0m 131.5   \u001b[0m | \u001b[0m 41.3    \u001b[0m | \u001b[0m 0.917   \u001b[0m | \u001b[0m 6.915   \u001b[0m | \u001b[0m 0.7348  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.32111\tvalid_1's multi_logloss: 1.4895\n",
      "[200]\ttraining's multi_logloss: 1.30201\tvalid_1's multi_logloss: 1.48647\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 1.486   \u001b[0m | \u001b[0m 0.5641  \u001b[0m | \u001b[0m 0.08924 \u001b[0m | \u001b[0m 459.9   \u001b[0m | \u001b[0m 8.585   \u001b[0m | \u001b[0m 18.64   \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 320.8   \u001b[0m | \u001b[0m 36.41   \u001b[0m | \u001b[0m 34.1    \u001b[0m | \u001b[0m 2.091   \u001b[0m | \u001b[0m 0.7598  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 1.476   \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 0.09729 \u001b[0m | \u001b[0m 403.1   \u001b[0m | \u001b[0m 8.385   \u001b[0m | \u001b[0m 185.4   \u001b[0m | \u001b[0m 43.46   \u001b[0m | \u001b[0m 66.16   \u001b[0m | \u001b[0m 43.93   \u001b[0m | \u001b[0m 4.322   \u001b[0m | \u001b[0m 9.159   \u001b[0m | \u001b[0m 0.9633  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.4032\tvalid_1's multi_logloss: 1.51403\n",
      "[200]\ttraining's multi_logloss: 1.29553\tvalid_1's multi_logloss: 1.48407\n",
      "[300]\ttraining's multi_logloss: 1.22851\tvalid_1's multi_logloss: 1.47569\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.5489  \u001b[0m | \u001b[0m 0.03395 \u001b[0m | \u001b[0m 64.96   \u001b[0m | \u001b[0m 13.84   \u001b[0m | \u001b[0m 65.5    \u001b[0m | \u001b[0m 37.87   \u001b[0m | \u001b[0m 355.0   \u001b[0m | \u001b[0m 48.02   \u001b[0m | \u001b[0m 21.2    \u001b[0m | \u001b[0m 9.522   \u001b[0m | \u001b[0m 0.599   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.26332\tvalid_1's multi_logloss: 1.48477\n",
      "[200]\ttraining's multi_logloss: 1.21912\tvalid_1's multi_logloss: 1.48143\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 0.6315  \u001b[0m | \u001b[0m 0.08962 \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 183.9   \u001b[0m | \u001b[0m 8.872   \u001b[0m | \u001b[0m 201.0   \u001b[0m | \u001b[0m 38.73   \u001b[0m | \u001b[0m 27.65   \u001b[0m | \u001b[0m 1.969   \u001b[0m | \u001b[0m 0.8596  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.876516\tvalid_1's multi_logloss: 1.48171\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 1.478   \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.08917 \u001b[0m | \u001b[0m 241.4   \u001b[0m | \u001b[0m 9.347   \u001b[0m | \u001b[0m 170.4   \u001b[0m | \u001b[0m 22.65   \u001b[0m | \u001b[0m 359.8   \u001b[0m | \u001b[0m 58.81   \u001b[0m | \u001b[0m 1.244   \u001b[0m | \u001b[0m 9.426   \u001b[0m | \u001b[0m 0.8205  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.51577\tvalid_1's multi_logloss: 1.58551\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 1.572   \u001b[0m | \u001b[0m 0.6271  \u001b[0m | \u001b[0m 0.01607 \u001b[0m | \u001b[0m 433.6   \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 69.55   \u001b[0m | \u001b[0m 6.576   \u001b[0m | \u001b[0m 115.7   \u001b[0m | \u001b[0m 42.59   \u001b[0m | \u001b[0m 40.2    \u001b[0m | \u001b[0m 9.527   \u001b[0m | \u001b[0m 0.6237  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.63237\tvalid_1's multi_logloss: 1.66074\n",
      "[200]\ttraining's multi_logloss: 1.54286\tvalid_1's multi_logloss: 1.59278\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 1.568   \u001b[0m | \u001b[0m 0.9753  \u001b[0m | \u001b[0m 0.007141\u001b[0m | \u001b[0m 150.5   \u001b[0m | \u001b[0m 10.85   \u001b[0m | \u001b[0m 126.7   \u001b[0m | \u001b[0m 29.2    \u001b[0m | \u001b[0m 265.4   \u001b[0m | \u001b[0m 27.8    \u001b[0m | \u001b[0m 38.66   \u001b[0m | \u001b[0m 5.93    \u001b[0m | \u001b[0m 0.6262  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.19085\tvalid_1's multi_logloss: 1.49426\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 1.493   \u001b[0m | \u001b[0m 0.8518  \u001b[0m | \u001b[0m 0.05792 \u001b[0m | \u001b[0m 97.41   \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 21.1    \u001b[0m | \u001b[0m 3.056   \u001b[0m | \u001b[0m 111.2   \u001b[0m | \u001b[0m 59.99   \u001b[0m | \u001b[0m 26.46   \u001b[0m | \u001b[0m 2.452   \u001b[0m | \u001b[0m 0.7119  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.49773\tvalid_1's multi_logloss: 1.56149\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 1.554   \u001b[0m | \u001b[0m 0.934   \u001b[0m | \u001b[0m 0.02159 \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 9.834   \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 9.714   \u001b[0m | \u001b[0m 109.6   \u001b[0m | \u001b[0m 49.51   \u001b[0m | \u001b[0m 44.53   \u001b[0m | \u001b[0m 6.01    \u001b[0m | \u001b[0m 0.7984  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.4836\tvalid_1's multi_logloss: 1.54338\n",
      "[200]\ttraining's multi_logloss: 1.41917\tvalid_1's multi_logloss: 1.50869\n",
      "[300]\ttraining's multi_logloss: 1.39441\tvalid_1's multi_logloss: 1.49925\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 1.497   \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 0.02929 \u001b[0m | \u001b[0m 197.3   \u001b[0m | \u001b[0m 11.55   \u001b[0m | \u001b[0m 80.52   \u001b[0m | \u001b[0m 42.96   \u001b[0m | \u001b[0m 372.8   \u001b[0m | \u001b[0m 43.49   \u001b[0m | \u001b[0m 44.28   \u001b[0m | \u001b[0m 1.702   \u001b[0m | \u001b[0m 0.8876  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.7715\tvalid_1's multi_logloss: 1.77995\n",
      "[200]\ttraining's multi_logloss: 1.71489\tvalid_1's multi_logloss: 1.73072\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 1.705   \u001b[0m | \u001b[95m 0.7841  \u001b[0m | \u001b[95m 0.001698\u001b[0m | \u001b[95m 143.8   \u001b[0m | \u001b[95m 11.97   \u001b[0m | \u001b[95m 131.1   \u001b[0m | \u001b[95m 22.38   \u001b[0m | \u001b[95m 267.3   \u001b[0m | \u001b[95m 26.95   \u001b[0m | \u001b[95m 35.91   \u001b[0m | \u001b[95m 3.059   \u001b[0m | \u001b[95m 0.9364  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.53578\tvalid_1's multi_logloss: 1.59146\n",
      "[200]\ttraining's multi_logloss: 1.44465\tvalid_1's multi_logloss: 1.53509\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 1.518   \u001b[0m | \u001b[0m 0.6939  \u001b[0m | \u001b[0m 0.01438 \u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 9.234   \u001b[0m | \u001b[0m 130.8   \u001b[0m | \u001b[0m 16.24   \u001b[0m | \u001b[0m 267.0   \u001b[0m | \u001b[0m 33.2    \u001b[0m | \u001b[0m 37.03   \u001b[0m | \u001b[0m 6.381   \u001b[0m | \u001b[0m 0.8914  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.73229\tvalid_1's multi_logloss: 1.74514\n",
      "[200]\ttraining's multi_logloss: 1.65842\tvalid_1's multi_logloss: 1.68181\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 1.654   \u001b[0m | \u001b[0m 0.5857  \u001b[0m | \u001b[0m 0.003166\u001b[0m | \u001b[0m 156.3   \u001b[0m | \u001b[0m 12.96   \u001b[0m | \u001b[0m 132.2   \u001b[0m | \u001b[0m 27.25   \u001b[0m | \u001b[0m 263.8   \u001b[0m | \u001b[0m 33.68   \u001b[0m | \u001b[0m 40.42   \u001b[0m | \u001b[0m 4.588   \u001b[0m | \u001b[0m 0.6872  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.43219\tvalid_1's multi_logloss: 1.52562\n",
      "[200]\ttraining's multi_logloss: 1.3568\tvalid_1's multi_logloss: 1.49769\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 1.493   \u001b[0m | \u001b[0m 0.8053  \u001b[0m | \u001b[0m 0.03371 \u001b[0m | \u001b[0m 149.3   \u001b[0m | \u001b[0m 9.995   \u001b[0m | \u001b[0m 124.1   \u001b[0m | \u001b[0m 33.0    \u001b[0m | \u001b[0m 256.9   \u001b[0m | \u001b[0m 34.12   \u001b[0m | \u001b[0m 35.56   \u001b[0m | \u001b[0m 4.195   \u001b[0m | \u001b[0m 0.709   \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.45655\tvalid_1's multi_logloss: 1.54116\n",
      "[200]\ttraining's multi_logloss: 1.37857\tvalid_1's multi_logloss: 1.50645\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 1.499   \u001b[0m | \u001b[0m 0.7364  \u001b[0m | \u001b[0m 0.02748 \u001b[0m | \u001b[0m 130.3   \u001b[0m | \u001b[0m 12.49   \u001b[0m | \u001b[0m 128.0   \u001b[0m | \u001b[0m 17.68   \u001b[0m | \u001b[0m 271.8   \u001b[0m | \u001b[0m 32.86   \u001b[0m | \u001b[0m 39.23   \u001b[0m | \u001b[0m 9.013   \u001b[0m | \u001b[0m 0.9734  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.31796\tvalid_1's multi_logloss: 1.49761\n",
      "[200]\ttraining's multi_logloss: 1.30981\tvalid_1's multi_logloss: 1.49651\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 1.497   \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.09832 \u001b[0m | \u001b[0m 154.9   \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 127.2   \u001b[0m | \u001b[0m 17.46   \u001b[0m | \u001b[0m 273.1   \u001b[0m | \u001b[0m 48.4    \u001b[0m | \u001b[0m 37.14   \u001b[0m | \u001b[0m 7.111   \u001b[0m | \u001b[0m 0.7397  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 1.546   \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 0.03315 \u001b[0m | \u001b[0m 161.3   \u001b[0m | \u001b[0m 12.55   \u001b[0m | \u001b[0m 14.37   \u001b[0m | \u001b[0m 41.18   \u001b[0m | \u001b[0m 67.13   \u001b[0m | \u001b[0m 31.54   \u001b[0m | \u001b[0m 26.31   \u001b[0m | \u001b[0m 4.001   \u001b[0m | \u001b[0m 0.5772  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.40283\tvalid_1's multi_logloss: 1.52235\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 0.03763 \u001b[0m | \u001b[0m 435.9   \u001b[0m | \u001b[0m 9.637   \u001b[0m | \u001b[0m 83.84   \u001b[0m | \u001b[0m 2.188   \u001b[0m | \u001b[0m 115.3   \u001b[0m | \u001b[0m 37.38   \u001b[0m | \u001b[0m 41.65   \u001b[0m | \u001b[0m 6.016   \u001b[0m | \u001b[0m 0.8648  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 1.566   \u001b[0m | \u001b[0m 0.5648  \u001b[0m | \u001b[0m 0.03875 \u001b[0m | \u001b[0m 65.62   \u001b[0m | \u001b[0m 15.36   \u001b[0m | \u001b[0m 88.48   \u001b[0m | \u001b[0m 1.118   \u001b[0m | \u001b[0m 51.35   \u001b[0m | \u001b[0m 35.48   \u001b[0m | \u001b[0m 38.55   \u001b[0m | \u001b[0m 8.34    \u001b[0m | \u001b[0m 0.9788  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 1.591   \u001b[0m | \u001b[0m 0.8235  \u001b[0m | \u001b[0m 0.01878 \u001b[0m | \u001b[0m 470.1   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 175.2   \u001b[0m | \u001b[0m 10.43   \u001b[0m | \u001b[0m 60.61   \u001b[0m | \u001b[0m 32.98   \u001b[0m | \u001b[0m 16.55   \u001b[0m | \u001b[0m 8.837   \u001b[0m | \u001b[0m 0.5008  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.14812\tvalid_1's multi_logloss: 1.47153\n",
      "[200]\ttraining's multi_logloss: 0.930613\tvalid_1's multi_logloss: 1.47126\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 0.05377 \u001b[0m | \u001b[0m 84.75   \u001b[0m | \u001b[0m 10.7    \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 45.29   \u001b[0m | \u001b[0m 250.6   \u001b[0m | \u001b[0m 50.68   \u001b[0m | \u001b[0m 0.3493  \u001b[0m | \u001b[0m 9.987   \u001b[0m | \u001b[0m 0.5655  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.42288\tvalid_1's multi_logloss: 1.51809\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 1.504   \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 0.04093 \u001b[0m | \u001b[0m 142.4   \u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 39.88   \u001b[0m | \u001b[0m 35.72   \u001b[0m | \u001b[0m 143.9   \u001b[0m | \u001b[0m 44.61   \u001b[0m | \u001b[0m 39.49   \u001b[0m | \u001b[0m 3.706   \u001b[0m | \u001b[0m 0.9244  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.60968\tvalid_1's multi_logloss: 1.66002\n",
      "[200]\ttraining's multi_logloss: 1.48941\tvalid_1's multi_logloss: 1.58278\n",
      "[300]\ttraining's multi_logloss: 1.41011\tvalid_1's multi_logloss: 1.54229\n",
      "[400]\ttraining's multi_logloss: 1.35069\tvalid_1's multi_logloss: 1.51879\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 1.507   \u001b[0m | \u001b[0m 0.6451  \u001b[0m | \u001b[0m 0.005897\u001b[0m | \u001b[0m 171.4   \u001b[0m | \u001b[0m 9.761   \u001b[0m | \u001b[0m 45.17   \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 478.6   \u001b[0m | \u001b[0m 44.85   \u001b[0m | \u001b[0m 14.2    \u001b[0m | \u001b[0m 2.572   \u001b[0m | \u001b[0m 0.6846  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.42673\tvalid_1's multi_logloss: 1.53747\n",
      "[200]\ttraining's multi_logloss: 1.28012\tvalid_1's multi_logloss: 1.48739\n",
      "[300]\ttraining's multi_logloss: 1.18281\tvalid_1's multi_logloss: 1.47247\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 1.472   \u001b[0m | \u001b[0m 0.6066  \u001b[0m | \u001b[0m 0.01659 \u001b[0m | \u001b[0m 45.05   \u001b[0m | \u001b[0m 10.16   \u001b[0m | \u001b[0m 139.3   \u001b[0m | \u001b[0m 44.95   \u001b[0m | \u001b[0m 310.2   \u001b[0m | \u001b[0m 58.22   \u001b[0m | \u001b[0m 2.522   \u001b[0m | \u001b[0m 5.478   \u001b[0m | \u001b[0m 0.6667  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.4068\tvalid_1's multi_logloss: 1.51909\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 0.7192  \u001b[0m | \u001b[0m 0.04793 \u001b[0m | \u001b[0m 441.6   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 77.08   \u001b[0m | \u001b[0m 10.36   \u001b[0m | \u001b[0m 114.2   \u001b[0m | \u001b[0m 37.29   \u001b[0m | \u001b[0m 47.79   \u001b[0m | \u001b[0m 8.207   \u001b[0m | \u001b[0m 0.5652  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.42252\tvalid_1's multi_logloss: 1.52161\n",
      "[200]\ttraining's multi_logloss: 1.37295\tvalid_1's multi_logloss: 1.5036\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 1.502   \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.04156 \u001b[0m | \u001b[0m 166.0   \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 127.6   \u001b[0m | \u001b[0m 23.28   \u001b[0m | \u001b[0m 263.5   \u001b[0m | \u001b[0m 28.08   \u001b[0m | \u001b[0m 44.31   \u001b[0m | \u001b[0m 7.457   \u001b[0m | \u001b[0m 0.8313  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 1.487   \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.08752 \u001b[0m | \u001b[0m 473.3   \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 176.1   \u001b[0m | \u001b[0m 1.579   \u001b[0m | \u001b[0m 59.59   \u001b[0m | \u001b[0m 29.46   \u001b[0m | \u001b[0m 18.15   \u001b[0m | \u001b[0m 8.241   \u001b[0m | \u001b[0m 0.8668  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.24665\tvalid_1's multi_logloss: 1.48257\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 1.479   \u001b[0m | \u001b[0m 0.9577  \u001b[0m | \u001b[0m 0.08082 \u001b[0m | \u001b[0m 29.33   \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 196.2   \u001b[0m | \u001b[0m 44.87   \u001b[0m | \u001b[0m 126.5   \u001b[0m | \u001b[0m 26.77   \u001b[0m | \u001b[0m 19.69   \u001b[0m | \u001b[0m 5.971   \u001b[0m | \u001b[0m 0.7548  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.53474\tvalid_1's multi_logloss: 1.58528\n",
      "[200]\ttraining's multi_logloss: 1.45052\tvalid_1's multi_logloss: 1.53331\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 0.7853  \u001b[0m | \u001b[0m 0.0161  \u001b[0m | \u001b[0m 156.8   \u001b[0m | \u001b[0m 12.8    \u001b[0m | \u001b[0m 143.6   \u001b[0m | \u001b[0m 30.42   \u001b[0m | \u001b[0m 277.0   \u001b[0m | \u001b[0m 34.73   \u001b[0m | \u001b[0m 39.53   \u001b[0m | \u001b[0m 9.989   \u001b[0m | \u001b[0m 0.8632  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.48284\tvalid_1's multi_logloss: 1.56367\n",
      "[200]\ttraining's multi_logloss: 1.3603\tvalid_1's multi_logloss: 1.5077\n",
      "[300]\ttraining's multi_logloss: 1.27959\tvalid_1's multi_logloss: 1.48811\n",
      "[400]\ttraining's multi_logloss: 1.21566\tvalid_1's multi_logloss: 1.47932\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 1.476   \u001b[0m | \u001b[0m 0.641   \u001b[0m | \u001b[0m 0.01511 \u001b[0m | \u001b[0m 474.2   \u001b[0m | \u001b[0m 11.84   \u001b[0m | \u001b[0m 37.07   \u001b[0m | \u001b[0m 27.51   \u001b[0m | \u001b[0m 468.0   \u001b[0m | \u001b[0m 34.64   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 6.111   \u001b[0m | \u001b[0m 0.7433  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.22686\tvalid_1's multi_logloss: 1.48313\n",
      "[200]\ttraining's multi_logloss: 1.17249\tvalid_1's multi_logloss: 1.48074\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 0.8572  \u001b[0m | \u001b[0m 0.09739 \u001b[0m | \u001b[0m 248.8   \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 30.63   \u001b[0m | \u001b[0m 410.8   \u001b[0m | \u001b[0m 54.97   \u001b[0m | \u001b[0m 24.66   \u001b[0m | \u001b[0m 2.474   \u001b[0m | \u001b[0m 0.8755  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.13616\tvalid_1's multi_logloss: 1.47646\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.9843  \u001b[0m | \u001b[0m 0.05701 \u001b[0m | \u001b[0m 109.6   \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 196.3   \u001b[0m | \u001b[0m 39.79   \u001b[0m | \u001b[0m 192.8   \u001b[0m | \u001b[0m 56.91   \u001b[0m | \u001b[0m 4.085   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 0.9406  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.34538\tvalid_1's multi_logloss: 1.49355\n",
      "[200]\ttraining's multi_logloss: 1.32359\tvalid_1's multi_logloss: 1.49011\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 1.49    \u001b[0m | \u001b[0m 0.7072  \u001b[0m | \u001b[0m 0.0825  \u001b[0m | \u001b[0m 157.7   \u001b[0m | \u001b[0m 11.79   \u001b[0m | \u001b[0m 119.5   \u001b[0m | \u001b[0m 29.45   \u001b[0m | \u001b[0m 263.7   \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 36.46   \u001b[0m | \u001b[0m 5.519   \u001b[0m | \u001b[0m 0.7987  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.42495\tvalid_1's multi_logloss: 1.51698\n",
      "[200]\ttraining's multi_logloss: 1.38441\tvalid_1's multi_logloss: 1.50206\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 1.501   \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.04748 \u001b[0m | \u001b[0m 154.5   \u001b[0m | \u001b[0m 11.7    \u001b[0m | \u001b[0m 125.9   \u001b[0m | \u001b[0m 31.37   \u001b[0m | \u001b[0m 269.0   \u001b[0m | \u001b[0m 27.75   \u001b[0m | \u001b[0m 46.0    \u001b[0m | \u001b[0m 3.26    \u001b[0m | \u001b[0m 0.5198  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.41958\tvalid_1's multi_logloss: 1.52321\n",
      "[200]\ttraining's multi_logloss: 1.36336\tvalid_1's multi_logloss: 1.50159\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 0.692   \u001b[0m | \u001b[0m 0.03881 \u001b[0m | \u001b[0m 447.6   \u001b[0m | \u001b[0m 12.21   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 4.126   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 45.34   \u001b[0m | \u001b[0m 42.45   \u001b[0m | \u001b[0m 5.131   \u001b[0m | \u001b[0m 0.8917  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.32735\tvalid_1's multi_logloss: 1.49086\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 1.49    \u001b[0m | \u001b[0m 0.6007  \u001b[0m | \u001b[0m 0.08275 \u001b[0m | \u001b[0m 286.0   \u001b[0m | \u001b[0m 13.52   \u001b[0m | \u001b[0m 191.0   \u001b[0m | \u001b[0m 10.98   \u001b[0m | \u001b[0m 103.4   \u001b[0m | \u001b[0m 49.5    \u001b[0m | \u001b[0m 33.48   \u001b[0m | \u001b[0m 9.573   \u001b[0m | \u001b[0m 0.5761  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.39041\tvalid_1's multi_logloss: 1.52253\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 0.03558 \u001b[0m | \u001b[0m 426.9   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 82.85   \u001b[0m | \u001b[0m 3.853   \u001b[0m | \u001b[0m 115.8   \u001b[0m | \u001b[0m 33.7    \u001b[0m | \u001b[0m 38.26   \u001b[0m | \u001b[0m 2.822   \u001b[0m | \u001b[0m 0.9629  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.48607\tvalid_1's multi_logloss: 1.56105\n",
      "[200]\ttraining's multi_logloss: 1.38766\tvalid_1's multi_logloss: 1.51363\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 1.501   \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.01858 \u001b[0m | \u001b[0m 149.4   \u001b[0m | \u001b[0m 15.59   \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 24.37   \u001b[0m | \u001b[0m 266.3   \u001b[0m | \u001b[0m 43.42   \u001b[0m | \u001b[0m 29.64   \u001b[0m | \u001b[0m 8.166   \u001b[0m | \u001b[0m 0.5638  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 1.507   \u001b[0m | \u001b[0m 0.635   \u001b[0m | \u001b[0m 0.0422  \u001b[0m | \u001b[0m 472.7   \u001b[0m | \u001b[0m 9.306   \u001b[0m | \u001b[0m 176.6   \u001b[0m | \u001b[0m 20.29   \u001b[0m | \u001b[0m 72.42   \u001b[0m | \u001b[0m 34.85   \u001b[0m | \u001b[0m 13.39   \u001b[0m | \u001b[0m 6.557   \u001b[0m | \u001b[0m 0.8249  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's multi_logloss: 1.57853\tvalid_1's multi_logloss: 1.61829\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 1.61    \u001b[0m | \u001b[0m 0.7846  \u001b[0m | \u001b[0m 0.011   \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 191.9   \u001b[0m | \u001b[0m 17.14   \u001b[0m | \u001b[0m 108.9   \u001b[0m | \u001b[0m 54.02   \u001b[0m | \u001b[0m 39.89   \u001b[0m | \u001b[0m 4.221   \u001b[0m | \u001b[0m 0.6714  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.48559\tvalid_1's multi_logloss: 1.58113\n",
      "[200]\ttraining's multi_logloss: 1.34494\tvalid_1's multi_logloss: 1.51776\n",
      "[300]\ttraining's multi_logloss: 1.24893\tvalid_1's multi_logloss: 1.49299\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 1.483   \u001b[0m | \u001b[0m 0.5358  \u001b[0m | \u001b[0m 0.0126  \u001b[0m | \u001b[0m 246.8   \u001b[0m | \u001b[0m 13.32   \u001b[0m | \u001b[0m 117.5   \u001b[0m | \u001b[0m 5.412   \u001b[0m | \u001b[0m 383.1   \u001b[0m | \u001b[0m 41.53   \u001b[0m | \u001b[0m 13.23   \u001b[0m | \u001b[0m 6.24    \u001b[0m | \u001b[0m 0.5461  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 0.798755\tvalid_1's multi_logloss: 1.47969\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.06378 \u001b[0m | \u001b[0m 352.4   \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 139.0   \u001b[0m | \u001b[0m 6.911   \u001b[0m | \u001b[0m 262.4   \u001b[0m | \u001b[0m 45.78   \u001b[0m | \u001b[0m 1.28    \u001b[0m | \u001b[0m 8.062   \u001b[0m | \u001b[0m 0.5683  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.36514\tvalid_1's multi_logloss: 1.49671\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 1.496   \u001b[0m | \u001b[0m 0.7734  \u001b[0m | \u001b[0m 0.08886 \u001b[0m | \u001b[0m 293.6   \u001b[0m | \u001b[0m 10.28   \u001b[0m | \u001b[0m 184.6   \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 110.8   \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 41.28   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.7115  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.40141\tvalid_1's multi_logloss: 1.50705\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 1.503   \u001b[0m | \u001b[0m 0.519   \u001b[0m | \u001b[0m 0.06869 \u001b[0m | \u001b[0m 276.8   \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 191.8   \u001b[0m | \u001b[0m 25.38   \u001b[0m | \u001b[0m 116.6   \u001b[0m | \u001b[0m 56.6    \u001b[0m | \u001b[0m 43.98   \u001b[0m | \u001b[0m 4.888   \u001b[0m | \u001b[0m 0.7652  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.38309\tvalid_1's multi_logloss: 1.50829\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 1.507   \u001b[0m | \u001b[0m 0.9469  \u001b[0m | \u001b[0m 0.08172 \u001b[0m | \u001b[0m 467.8   \u001b[0m | \u001b[0m 13.47   \u001b[0m | \u001b[0m 122.7   \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 177.0   \u001b[0m | \u001b[0m 53.74   \u001b[0m | \u001b[0m 48.6    \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 0.925   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 1.591   \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 0.02278 \u001b[0m | \u001b[0m 171.5   \u001b[0m | \u001b[0m 14.73   \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 38.41   \u001b[0m | \u001b[0m 62.69   \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 34.16   \u001b[0m | \u001b[0m 7.277   \u001b[0m | \u001b[0m 0.6081  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.36683\tvalid_1's multi_logloss: 1.50042\n",
      "[200]\ttraining's multi_logloss: 1.36042\tvalid_1's multi_logloss: 1.49916\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 1.499   \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.09359 \u001b[0m | \u001b[0m 131.6   \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 132.1   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 260.5   \u001b[0m | \u001b[0m 24.46   \u001b[0m | \u001b[0m 43.12   \u001b[0m | \u001b[0m 1.287   \u001b[0m | \u001b[0m 0.9477  \u001b[0m |\n",
      "[100]\ttraining's multi_logloss: 1.55175\tvalid_1's multi_logloss: 1.59738\n",
      "[200]\ttraining's multi_logloss: 1.47055\tvalid_1's multi_logloss: 1.54297\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 1.527   \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.01438 \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 8.545   \u001b[0m | \u001b[0m 130.5   \u001b[0m | \u001b[0m 24.58   \u001b[0m | \u001b[0m 268.6   \u001b[0m | \u001b[0m 30.35   \u001b[0m | \u001b[0m 46.73   \u001b[0m | \u001b[0m 2.793   \u001b[0m | \u001b[0m 0.7915  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 1.48    \u001b[0m | \u001b[0m 0.8563  \u001b[0m | \u001b[0m 0.09341 \u001b[0m | \u001b[0m 480.0   \u001b[0m | \u001b[0m 8.833   \u001b[0m | \u001b[0m 181.1   \u001b[0m | \u001b[0m 8.537   \u001b[0m | \u001b[0m 69.96   \u001b[0m | \u001b[0m 53.74   \u001b[0m | \u001b[0m 11.21   \u001b[0m | \u001b[0m 6.605   \u001b[0m | \u001b[0m 0.944   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 1.52    \u001b[0m | \u001b[0m 0.7254  \u001b[0m | \u001b[0m 0.04755 \u001b[0m | \u001b[0m 285.4   \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 6.181   \u001b[0m | \u001b[0m 98.45   \u001b[0m | \u001b[0m 52.82   \u001b[0m | \u001b[0m 48.93   \u001b[0m | \u001b[0m 7.855   \u001b[0m | \u001b[0m 0.6888  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 1.514   \u001b[0m | \u001b[0m 0.7355  \u001b[0m | \u001b[0m 0.07689 \u001b[0m | \u001b[0m 169.0   \u001b[0m | \u001b[0m 8.207   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 43.15   \u001b[0m | \u001b[0m 53.71   \u001b[0m | \u001b[0m 32.02   \u001b[0m | \u001b[0m 33.82   \u001b[0m | \u001b[0m 6.033   \u001b[0m | \u001b[0m 0.9246  \u001b[0m |\n",
      "=============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f = lgb_log_loss_eval, pbounds=bayesian_params, random_state=1000)\n",
    "lgbBO.maximize(init_points=5, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426bc1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6180766132143152, 1.4771480931188807, 1.4986236823777845, 1.4865929511101474, 1.4864684198990108, 1.4761457599925478, 1.4732015788119721, 1.481429941517693, 1.4779121866594425, 1.571835428077632, 1.5684302235359127, 1.4927936611443855, 1.554248309366624, 1.4968960772406232, 1.7047804606751118, 1.5183652754293264, 1.653741736036426, 1.493191892742638, 1.4985408851282322, 1.4965054169759506, 1.5456786858646698, 1.5161884829622883, 1.5661772260059434, 1.5912441544058429, 1.468628214769404, 1.5037108485938704, 1.5069424997581757, 1.4715535991096913, 1.5147208647206722, 1.5018880256054477, 1.4871269194637353, 1.4794706466045988, 1.5160707358615568, 1.475861739780996, 1.480647345395523, 1.4766480233963675, 1.4901128297295496, 1.5013526930356011, 1.499800473009222, 1.4902029572632227, 1.5154260725926423, 1.5009286342511807, 1.5073718377024625, 1.6095818613813475, 1.483321475963915, 1.4773403259494458, 1.4956001395437006, 1.5034134247978768, 1.5066672712970568, 1.5909097497759395, 1.4991613688479695, 1.5267935168587707, 1.4800613729231722, 1.5195210252223037, 1.5143661801165234]\n",
      "maximum target index: 24\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159c1eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 1.468628214769404, 'params': {'colsample_bytree': 0.7332583469184908, 'learning_rate': 0.05376702188186737, 'max_bin': 84.74524468918648, 'max_depth': 10.69908199214511, 'min_child_samples': 180.21851856592102, 'min_child_weight': 45.29455927988186, 'n_estimators': 250.61717140680972, 'num_leaves': 50.677188681346735, 'reg_alpha': 0.34933638595536765, 'reg_lambda': 9.987015785769142, 'subsample': 0.5655322532561203}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc8505",
   "metadata": {},
   "source": [
    "# *OOF 스태킹*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04f04938",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv' , encoding = 'cp949').group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df2c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939f18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b59fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2a0b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 499), (14380, 499))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape, X_te_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df4e08b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof_ver2 = np.zeros((X_new.shape[0], 19))\n",
    "lgb_oof_ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "236f8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "# FE\n",
    "from scipy.signal import find_peaks, peak_widths, peak_prominences\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ensemble\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0593f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca751849",
   "metadata": {},
   "source": [
    "{'target': 1.468628214769404, 'params': {'colsample_bytree': 0.7332583469184908, 'learning_rate': 0.05376702188186737, 'max_bin': 84.74524468918648, 'max_depth': 10.69908199214511, 'min_child_samples': 180.21851856592102, 'min_child_weight': 45.29455927988186, 'n_estimators': 250.61717140680972, 'num_leaves': 50.677188681346735, 'reg_alpha': 0.34933638595536765, 'reg_lambda': 9.987015785769142, 'subsample': 0.5655322532561203}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17d36f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad346084",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(\n",
    "                objective='multiclass',\n",
    "                metric='multi_logloss',\n",
    "                nthread=4,\n",
    "                n_estimators=250,\n",
    "                learning_rate=0.05376702188186737,\n",
    "                max_bin=85,\n",
    "                max_depth=11,\n",
    "                num_leaves=51,\n",
    "                colsample_bytree=0.7332583469184908,\n",
    "                subsample=0.5655322532561203,\n",
    "                reg_alpha=0.34933638595536765,\n",
    "                reg_lambda=9.987015785769142,\n",
    "                min_child_samples=180,\n",
    "                min_child_weight=45.29455927988186,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                random_state=1000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90422e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9546172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.946542\tvalid_1's multi_logloss: 1.46057\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.943317\tvalid_1's multi_logloss: 1.47205\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.950352\tvalid_1's multi_logloss: 1.46583\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.947374\tvalid_1's multi_logloss: 1.48242\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.953174\tvalid_1's multi_logloss: 1.44846\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.950957\tvalid_1's multi_logloss: 1.45808\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.944224\tvalid_1's multi_logloss: 1.47485\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.954338\tvalid_1's multi_logloss: 1.44309\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.948094\tvalid_1's multi_logloss: 1.46306\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.943694\tvalid_1's multi_logloss: 1.48031\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "lgb ver2 logloss=  1.468677482365611\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.947736\tvalid_1's multi_logloss: 1.4563\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.95201\tvalid_1's multi_logloss: 1.46955\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.946846\tvalid_1's multi_logloss: 1.48775\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.948719\tvalid_1's multi_logloss: 1.44033\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.950159\tvalid_1's multi_logloss: 1.48628\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.947203\tvalid_1's multi_logloss: 1.46523\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.950799\tvalid_1's multi_logloss: 1.44943\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.945857\tvalid_1's multi_logloss: 1.4671\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.949828\tvalid_1's multi_logloss: 1.47046\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 0.944927\tvalid_1's multi_logloss: 1.47501\n",
      "*************************************************************************************\n",
      "Training has finished.\n",
      "lgb ver2 logloss=  1.461305891385887\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "mlogloss = []\n",
    "lgb_oof_ver2 = np.zeros((X_new.shape[0], 8))\n",
    "lgb_pred_ver2 = np.zeros((X_te_new.shape[0], 8))\n",
    "\n",
    "for X, X_test in [(X_new,X_te_new)]:\n",
    "    X= X.reset_index(drop=True)\n",
    "    for seed in [0,1000]:\n",
    "        kfold = StratifiedKFold(n_splits=n_splits, random_state= seed, shuffle=True)\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "            X_train, X_valid = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "            y_train, y_valid = y[trn_idx], y[val_idx]\n",
    "\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "            # Predict\n",
    "            lgb_pred_ver2 += clf.predict_proba(X_test) / (n_splits * 4)\n",
    "            lgb_oof_ver2[val_idx] += clf.predict_proba(X_valid) / 4\n",
    "            print('*'* 85)\n",
    "            print('Training has finished.')\n",
    "        print('lgb ver2 logloss= ', log_loss(y, lgb_oof_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ef66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oof = np.column_stack([lgb_oof_ver2])\n",
    "all_test = np.column_stack([lgb_pred_ver2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03d35f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067822</td>\n",
       "      <td>0.054536</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.077573</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.065385</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.166058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013510</td>\n",
       "      <td>0.034492</td>\n",
       "      <td>0.262041</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.149249</td>\n",
       "      <td>0.014670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416722</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.009564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.032353</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.158272</td>\n",
       "      <td>0.039870</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.196193</td>\n",
       "      <td>0.105315</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.036092</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.027880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0.150580</td>\n",
       "      <td>0.085071</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.039253</td>\n",
       "      <td>0.069070</td>\n",
       "      <td>0.056512</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.035419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.062192</td>\n",
       "      <td>0.184805</td>\n",
       "      <td>0.125750</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.062049</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.401242</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.067822  0.054536  0.018386  0.077573  0.037053  0.065385  0.013187   \n",
       "1      0.013510  0.034492  0.262041  0.007544  0.001991  0.016504  0.149249   \n",
       "2      0.416722  0.056078  0.004218  0.002852  0.010712  0.006276  0.001243   \n",
       "3      0.272008  0.066794  0.019654  0.021418  0.015980  0.075622  0.018960   \n",
       "4      0.441558  0.024129  0.004873  0.003393  0.017990  0.004705  0.001499   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  0.032353  0.221874  0.022800  0.008792  0.007031  0.158272  0.039870   \n",
       "14376  0.196193  0.105315  0.067057  0.034056  0.008402  0.036092  0.025006   \n",
       "14377  0.150580  0.085071  0.045800  0.039253  0.069070  0.056512  0.018296   \n",
       "14378  0.062192  0.184805  0.125750  0.005162  0.004608  0.062049  0.053561   \n",
       "14379  0.401242  0.026247  0.014846  0.005798  0.023528  0.020455  0.005925   \n",
       "\n",
       "              7  \n",
       "0      0.166058  \n",
       "1      0.014670  \n",
       "2      0.001900  \n",
       "3      0.009564  \n",
       "4      0.001853  \n",
       "...         ...  \n",
       "14375  0.009008  \n",
       "14376  0.027880  \n",
       "14377  0.035419  \n",
       "14378  0.001872  \n",
       "14379  0.001960  \n",
       "\n",
       "[14380 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35145ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19429, 499)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d582ccb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14380, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26e7a81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26729\tvalid_1's multi_logloss: 1.47699\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26749\tvalid_1's multi_logloss: 1.47308\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26524\tvalid_1's multi_logloss: 1.49973\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26925\tvalid_1's multi_logloss: 1.45977\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26416\tvalid_1's multi_logloss: 1.5157\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26757\tvalid_1's multi_logloss: 1.48055\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26722\tvalid_1's multi_logloss: 1.47002\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26681\tvalid_1's multi_logloss: 1.47921\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.26606\tvalid_1's multi_logloss: 1.48875\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[200]\ttraining's multi_logloss: 1.2637\tvalid_1's multi_logloss: 1.49921\n",
      "mean logloss=  nan\n"
     ]
    }
   ],
   "source": [
    "mlogloss = []\n",
    "n_splits = 10\n",
    "\n",
    "stk_oof_pred = np.zeros((all_oof.shape[0], 8))\n",
    "stk_test_pred = np.zeros((all_test.shape[0], 8))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits, random_state=1000, shuffle=True)\n",
    "for fold, (trn_idx, val_idx) in enumerate(kfold.split(all_oof, y)):\n",
    "    X_train, X_valid = all_oof[trn_idx], all_oof[val_idx]\n",
    "    y_train, y_valid = y[trn_idx], y[val_idx]\n",
    "            \n",
    "    clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "\n",
    "\n",
    "    stk_test_pred += clf.predict_proba(all_test) / n_splits\n",
    "    stk_oof_pred[val_idx] = clf.predict_proba(X_valid)\n",
    "    \n",
    "print('mean logloss= ',np.mean(mlogloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb104e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_test_pred = pd.DataFrame(stk_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "399a3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_test_pred = stk_test_pred.rename(columns = {0:'F20',1:'F30',2:'F40',3:'F50',4:'M20',5:'M30',6:'M40',7:'M50'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f597749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>F50</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "      <th>M50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156663</td>\n",
       "      <td>0.089070</td>\n",
       "      <td>0.053010</td>\n",
       "      <td>0.171149</td>\n",
       "      <td>0.122487</td>\n",
       "      <td>0.148980</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.229257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.055356</td>\n",
       "      <td>0.602576</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.030196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850770</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.006788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.312041</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>0.124847</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.839838</td>\n",
       "      <td>0.078835</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.009559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.290934</td>\n",
       "      <td>0.105399</td>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.310158</td>\n",
       "      <td>0.211895</td>\n",
       "      <td>0.235567</td>\n",
       "      <td>0.061233</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.084297</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.040503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>0.266065</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>0.070723</td>\n",
       "      <td>0.058905</td>\n",
       "      <td>0.198516</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.064971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>0.134219</td>\n",
       "      <td>0.349731</td>\n",
       "      <td>0.256458</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.073414</td>\n",
       "      <td>0.158630</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>0.786752</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.021003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F20       F30       F40       F50       M20       M30       M40  \\\n",
       "0      0.156663  0.089070  0.053010  0.171149  0.122487  0.148980  0.029384   \n",
       "1      0.007516  0.055356  0.602576  0.006623  0.002759  0.010515  0.284459   \n",
       "2      0.850770  0.087259  0.011270  0.006768  0.022990  0.011907  0.002247   \n",
       "3      0.350098  0.312041  0.032786  0.050447  0.124847  0.076881  0.020503   \n",
       "4      0.839838  0.078835  0.017156  0.007975  0.033409  0.010379  0.002850   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  0.049020  0.482403  0.027145  0.025468  0.009461  0.290934  0.105399   \n",
       "14376  0.310158  0.211895  0.235567  0.061233  0.022786  0.084297  0.033561   \n",
       "14377  0.266065  0.162950  0.070723  0.058905  0.198516  0.141810  0.036061   \n",
       "14378  0.134219  0.349731  0.256458  0.004877  0.015971  0.073414  0.158630   \n",
       "14379  0.786752  0.049616  0.018181  0.014831  0.068198  0.033033  0.008385   \n",
       "\n",
       "            M50  \n",
       "0      0.229257  \n",
       "1      0.030196  \n",
       "2      0.006788  \n",
       "3      0.032398  \n",
       "4      0.009559  \n",
       "...         ...  \n",
       "14375  0.010172  \n",
       "14376  0.040503  \n",
       "14377  0.064971  \n",
       "14378  0.006701  \n",
       "14379  0.021003  \n",
       "\n",
       "[14380 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d9410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_pd = pd.read_csv(os.path.abspath(\"../submission\")+\"/bbi_cat.csv\" , encoding ='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84840e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_id = test_id_pd['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73df6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.DataFrame({'ID':tst_id}),stk_test_pred],axis = 1)\n",
    "submission.to_csv('1round_third_lgbm_stk_oof_10.csv',index = False,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45cf7d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>F50</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "      <th>M50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.156663</td>\n",
       "      <td>0.089070</td>\n",
       "      <td>0.053010</td>\n",
       "      <td>0.171149</td>\n",
       "      <td>0.122487</td>\n",
       "      <td>0.148980</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.229257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.055356</td>\n",
       "      <td>0.602576</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.030196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.850770</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.006788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30005</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.312041</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>0.124847</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.032398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30007</td>\n",
       "      <td>0.839838</td>\n",
       "      <td>0.078835</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.009559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>49988</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.290934</td>\n",
       "      <td>0.105399</td>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>49990</td>\n",
       "      <td>0.310158</td>\n",
       "      <td>0.211895</td>\n",
       "      <td>0.235567</td>\n",
       "      <td>0.061233</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.084297</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.040503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>49992</td>\n",
       "      <td>0.266065</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>0.070723</td>\n",
       "      <td>0.058905</td>\n",
       "      <td>0.198516</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.064971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>49993</td>\n",
       "      <td>0.134219</td>\n",
       "      <td>0.349731</td>\n",
       "      <td>0.256458</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.073414</td>\n",
       "      <td>0.158630</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>49994</td>\n",
       "      <td>0.786752</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.021003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14380 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID       F20       F30       F40       F50       M20       M30  \\\n",
       "0      30001  0.156663  0.089070  0.053010  0.171149  0.122487  0.148980   \n",
       "1      30002  0.007516  0.055356  0.602576  0.006623  0.002759  0.010515   \n",
       "2      30003  0.850770  0.087259  0.011270  0.006768  0.022990  0.011907   \n",
       "3      30005  0.350098  0.312041  0.032786  0.050447  0.124847  0.076881   \n",
       "4      30007  0.839838  0.078835  0.017156  0.007975  0.033409  0.010379   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "14375  49988  0.049020  0.482403  0.027145  0.025468  0.009461  0.290934   \n",
       "14376  49990  0.310158  0.211895  0.235567  0.061233  0.022786  0.084297   \n",
       "14377  49992  0.266065  0.162950  0.070723  0.058905  0.198516  0.141810   \n",
       "14378  49993  0.134219  0.349731  0.256458  0.004877  0.015971  0.073414   \n",
       "14379  49994  0.786752  0.049616  0.018181  0.014831  0.068198  0.033033   \n",
       "\n",
       "            M40       M50  \n",
       "0      0.029384  0.229257  \n",
       "1      0.284459  0.030196  \n",
       "2      0.002247  0.006788  \n",
       "3      0.020503  0.032398  \n",
       "4      0.002850  0.009559  \n",
       "...         ...       ...  \n",
       "14375  0.105399  0.010172  \n",
       "14376  0.033561  0.040503  \n",
       "14377  0.036061  0.064971  \n",
       "14378  0.158630  0.006701  \n",
       "14379  0.008385  0.021003  \n",
       "\n",
       "[14380 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cdbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a03309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd78bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12018cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
